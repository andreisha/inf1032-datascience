{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION OF PARKISON'S DISEASE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipe :\n",
    "    * Jessica Vilar - 1613176\n",
    "    * Fernando Tancini - 1711799\n",
    "    * Andrea Mourelo - 1820000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('font', family='Arial')\n",
    "plt.rc('xtick', labelsize=12) \n",
    "plt.rc('ytick', labelsize=12) \n",
    "plt.rc('font', size=12) \n",
    "plt.rc('figure', figsize = (12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value: \n",
    "seed_value= 1001004  \n",
    "# 1. Set PYTHONHASHSEED environment variable at a fixed value: \n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "# 2. Set python built-in pseudo-random generator at a fixed value:\n",
    "import random\n",
    "random.seed(seed_value) \n",
    "# 3. Set numpy pseudo-random generator at a fixed value:\n",
    "np.random.seed(seed_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set Information:\n",
    "\n",
    "This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD. \n",
    "\n",
    "=> dados anonimizados mas cada linha nao corresponde a um individuo diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phon_R01_S01_6</td>\n",
       "      <td>120.552</td>\n",
       "      <td>131.162</td>\n",
       "      <td>113.787</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00463</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.01388</td>\n",
       "      <td>0.04701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06985</td>\n",
       "      <td>0.01222</td>\n",
       "      <td>21.378</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415564</td>\n",
       "      <td>0.825069</td>\n",
       "      <td>-4.242867</td>\n",
       "      <td>0.299111</td>\n",
       "      <td>2.187560</td>\n",
       "      <td>0.357775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>phon_R01_S02_1</td>\n",
       "      <td>120.267</td>\n",
       "      <td>137.244</td>\n",
       "      <td>114.820</td>\n",
       "      <td>0.00333</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.01608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02337</td>\n",
       "      <td>0.00607</td>\n",
       "      <td>24.886</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596040</td>\n",
       "      <td>0.764112</td>\n",
       "      <td>-5.634322</td>\n",
       "      <td>0.257682</td>\n",
       "      <td>1.854785</td>\n",
       "      <td>0.211756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>phon_R01_S02_2</td>\n",
       "      <td>107.332</td>\n",
       "      <td>113.840</td>\n",
       "      <td>104.315</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.00431</td>\n",
       "      <td>0.01567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02487</td>\n",
       "      <td>0.00344</td>\n",
       "      <td>26.892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.637420</td>\n",
       "      <td>0.763262</td>\n",
       "      <td>-6.167603</td>\n",
       "      <td>0.183721</td>\n",
       "      <td>2.064693</td>\n",
       "      <td>0.163755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>phon_R01_S02_3</td>\n",
       "      <td>95.730</td>\n",
       "      <td>132.068</td>\n",
       "      <td>91.754</td>\n",
       "      <td>0.00551</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.00880</td>\n",
       "      <td>0.02093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03218</td>\n",
       "      <td>0.01070</td>\n",
       "      <td>21.812</td>\n",
       "      <td>1</td>\n",
       "      <td>0.615551</td>\n",
       "      <td>0.773587</td>\n",
       "      <td>-5.498678</td>\n",
       "      <td>0.327769</td>\n",
       "      <td>2.322511</td>\n",
       "      <td>0.231571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phon_R01_S02_4</td>\n",
       "      <td>95.056</td>\n",
       "      <td>120.103</td>\n",
       "      <td>91.226</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.00332</td>\n",
       "      <td>0.00803</td>\n",
       "      <td>0.02838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04324</td>\n",
       "      <td>0.01022</td>\n",
       "      <td>21.862</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547037</td>\n",
       "      <td>0.798463</td>\n",
       "      <td>-5.011879</td>\n",
       "      <td>0.325996</td>\n",
       "      <td>2.432792</td>\n",
       "      <td>0.271362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phon_R01_S02_5</td>\n",
       "      <td>88.333</td>\n",
       "      <td>112.240</td>\n",
       "      <td>84.072</td>\n",
       "      <td>0.00505</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00254</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>0.00763</td>\n",
       "      <td>0.02143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.01166</td>\n",
       "      <td>21.118</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611137</td>\n",
       "      <td>0.776156</td>\n",
       "      <td>-5.249770</td>\n",
       "      <td>0.391002</td>\n",
       "      <td>2.407313</td>\n",
       "      <td>0.249740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phon_R01_S02_6</td>\n",
       "      <td>91.904</td>\n",
       "      <td>115.871</td>\n",
       "      <td>86.292</td>\n",
       "      <td>0.00540</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.00281</td>\n",
       "      <td>0.00336</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.02752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04272</td>\n",
       "      <td>0.01141</td>\n",
       "      <td>21.414</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583390</td>\n",
       "      <td>0.792520</td>\n",
       "      <td>-4.960234</td>\n",
       "      <td>0.363566</td>\n",
       "      <td>2.642476</td>\n",
       "      <td>0.275931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>phon_R01_S04_1</td>\n",
       "      <td>136.926</td>\n",
       "      <td>159.866</td>\n",
       "      <td>131.276</td>\n",
       "      <td>0.00293</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.00153</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.01259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.00581</td>\n",
       "      <td>25.703</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.646846</td>\n",
       "      <td>-6.547148</td>\n",
       "      <td>0.152813</td>\n",
       "      <td>2.041277</td>\n",
       "      <td>0.138512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>phon_R01_S04_2</td>\n",
       "      <td>139.173</td>\n",
       "      <td>179.139</td>\n",
       "      <td>76.556</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00165</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>0.00496</td>\n",
       "      <td>0.01642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02184</td>\n",
       "      <td>0.01041</td>\n",
       "      <td>24.889</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430166</td>\n",
       "      <td>0.665833</td>\n",
       "      <td>-5.660217</td>\n",
       "      <td>0.254989</td>\n",
       "      <td>2.519422</td>\n",
       "      <td>0.199889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>phon_R01_S04_3</td>\n",
       "      <td>152.845</td>\n",
       "      <td>163.305</td>\n",
       "      <td>75.836</td>\n",
       "      <td>0.00294</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.00149</td>\n",
       "      <td>0.00364</td>\n",
       "      <td>0.01828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03191</td>\n",
       "      <td>0.00609</td>\n",
       "      <td>24.922</td>\n",
       "      <td>1</td>\n",
       "      <td>0.474791</td>\n",
       "      <td>0.654027</td>\n",
       "      <td>-6.105098</td>\n",
       "      <td>0.203653</td>\n",
       "      <td>2.125618</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0   phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1   phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2   phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3   phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4   phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "5   phon_R01_S01_6      120.552       131.162       113.787         0.00968   \n",
       "6   phon_R01_S02_1      120.267       137.244       114.820         0.00333   \n",
       "7   phon_R01_S02_2      107.332       113.840       104.315         0.00290   \n",
       "8   phon_R01_S02_3       95.730       132.068        91.754         0.00551   \n",
       "9   phon_R01_S02_4       95.056       120.103        91.226         0.00532   \n",
       "10  phon_R01_S02_5       88.333       112.240        84.072         0.00505   \n",
       "11  phon_R01_S02_6       91.904       115.871        86.292         0.00540   \n",
       "12  phon_R01_S04_1      136.926       159.866       131.276         0.00293   \n",
       "13  phon_R01_S04_2      139.173       179.139        76.556         0.00390   \n",
       "14  phon_R01_S04_3      152.845       163.305        75.836         0.00294   \n",
       "\n",
       "    MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
       "0            0.00007   0.00370   0.00554     0.01109       0.04374    ...      \n",
       "1            0.00008   0.00465   0.00696     0.01394       0.06134    ...      \n",
       "2            0.00009   0.00544   0.00781     0.01633       0.05233    ...      \n",
       "3            0.00009   0.00502   0.00698     0.01505       0.05492    ...      \n",
       "4            0.00011   0.00655   0.00908     0.01966       0.06425    ...      \n",
       "5            0.00008   0.00463   0.00750     0.01388       0.04701    ...      \n",
       "6            0.00003   0.00155   0.00202     0.00466       0.01608    ...      \n",
       "7            0.00003   0.00144   0.00182     0.00431       0.01567    ...      \n",
       "8            0.00006   0.00293   0.00332     0.00880       0.02093    ...      \n",
       "9            0.00006   0.00268   0.00332     0.00803       0.02838    ...      \n",
       "10           0.00006   0.00254   0.00330     0.00763       0.02143    ...      \n",
       "11           0.00006   0.00281   0.00336     0.00844       0.02752    ...      \n",
       "12           0.00002   0.00118   0.00153     0.00355       0.01259    ...      \n",
       "13           0.00003   0.00165   0.00208     0.00496       0.01642    ...      \n",
       "14           0.00002   0.00121   0.00149     0.00364       0.01828    ...      \n",
       "\n",
       "    Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0       0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1       0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2       0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3       0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4       0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "5       0.06985  0.01222  21.378       1  0.415564  0.825069 -4.242867   \n",
       "6       0.02337  0.00607  24.886       1  0.596040  0.764112 -5.634322   \n",
       "7       0.02487  0.00344  26.892       1  0.637420  0.763262 -6.167603   \n",
       "8       0.03218  0.01070  21.812       1  0.615551  0.773587 -5.498678   \n",
       "9       0.04324  0.01022  21.862       1  0.547037  0.798463 -5.011879   \n",
       "10      0.03237  0.01166  21.118       1  0.611137  0.776156 -5.249770   \n",
       "11      0.04272  0.01141  21.414       1  0.583390  0.792520 -4.960234   \n",
       "12      0.01968  0.00581  25.703       1  0.460600  0.646846 -6.547148   \n",
       "13      0.02184  0.01041  24.889       1  0.430166  0.665833 -5.660217   \n",
       "14      0.03191  0.00609  24.922       1  0.474791  0.654027 -6.105098   \n",
       "\n",
       "     spread2        D2       PPE  \n",
       "0   0.266482  2.301442  0.284654  \n",
       "1   0.335590  2.486855  0.368674  \n",
       "2   0.311173  2.342259  0.332634  \n",
       "3   0.334147  2.405554  0.368975  \n",
       "4   0.234513  2.332180  0.410335  \n",
       "5   0.299111  2.187560  0.357775  \n",
       "6   0.257682  1.854785  0.211756  \n",
       "7   0.183721  2.064693  0.163755  \n",
       "8   0.327769  2.322511  0.231571  \n",
       "9   0.325996  2.432792  0.271362  \n",
       "10  0.391002  2.407313  0.249740  \n",
       "11  0.363566  2.642476  0.275931  \n",
       "12  0.152813  2.041277  0.138512  \n",
       "13  0.254989  2.519422  0.199889  \n",
       "14  0.203653  2.125618  0.170100  \n",
       "\n",
       "[15 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'parkinsons.data'\n",
    "dfParkinson = pd.read_csv(filename)\n",
    "#dfParkinson.info()\n",
    "#dfParkinson.shape  # da (195,24)\n",
    "dfParkinson.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionando as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 48 147]\n"
     ]
    }
   ],
   "source": [
    "outcome_column = 'status'\n",
    "# status: 0: healthy, 1: Parkinson's\n",
    "outcome_labels = {0: 'healthy', 1:'Parkinson`s'}\n",
    "\n",
    "label_counts = np.bincount(dfParkinson.status)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais pessoas com parkinsons (1) do que sem (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MDVP:Fo(Hz)',\n",
       " 'MDVP:Fhi(Hz)',\n",
       " 'MDVP:Flo(Hz)',\n",
       " 'MDVP:Jitter(%)',\n",
       " 'MDVP:Jitter(Abs)',\n",
       " 'MDVP:RAP',\n",
       " 'MDVP:PPQ',\n",
       " 'Jitter:DDP',\n",
       " 'MDVP:Shimmer',\n",
       " 'MDVP:Shimmer(dB)',\n",
       " 'Shimmer:APQ3',\n",
       " 'Shimmer:APQ5',\n",
       " 'MDVP:APQ',\n",
       " 'Shimmer:DDA',\n",
       " 'NHR',\n",
       " 'HNR',\n",
       " 'RPDE',\n",
       " 'DFA',\n",
       " 'spread1',\n",
       " 'spread2',\n",
       " 'D2',\n",
       " 'PPE']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionamos todas as colunas como features, menos 'name' e 'status', essa última sendo nosso target.\n",
    "features = [col for col in dfParkinson.columns if col not in ['name', 'status']]\n",
    "features\n",
    "\n",
    "# Isso pode ser modificado para outros modelos mais tarde, ao por exemplo escolher menos colunas!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.199920e+02  1.573020e+02  7.499700e+01  7.840000e-03  7.000000e-05\n",
      "  3.700000e-03  5.540000e-03  1.109000e-02  4.374000e-02  4.260000e-01\n",
      "  2.182000e-02  3.130000e-02  2.971000e-02  6.545000e-02  2.211000e-02\n",
      "  2.103300e+01  4.147830e-01  8.152850e-01 -4.813031e+00  2.664820e-01\n",
      "  2.301442e+00  2.846540e-01]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# convert feature dataframe and label series to arrays\n",
    "X = np.array(dfParkinson[features]) # X = array de dados dos pacientes\n",
    "print(X[0, :])\n",
    "\n",
    "Y = np.array(dfParkinson[outcome_column]) # Y = outcome \"status\" dos pacientes\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino:  156 156\n",
      "Dados de teste:  39 39\n"
     ]
    }
   ],
   "source": [
    "# Separamos dados de treino e teste (20% de teste) para todos os modelos de K-NN\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dfTrain, dfTest = train_test_split(dfParkinson, test_size=0.2, \n",
    "                                   stratify=dfParkinson[outcome_column],random_state = seed_value)\n",
    "\n",
    "# convertemos dataframe de features e labels em arrays\n",
    "X_train = np.array(dfTrain[features])\n",
    "Y_train = np.array(dfTrain[outcome_column])\n",
    "\n",
    "# Imprimimos as dimensões das massas de treino\n",
    "print(\"Dados de treino: \", X_train.shape[0], Y_train.shape[0])\n",
    "\n",
    "# convertemos dataframe de features e labels em arrays\n",
    "X_test = np.array(dfTest[features])\n",
    "Y_test = np.array(dfTest[outcome_column])\n",
    "\n",
    "# Imprimimos as dimensões das massas de teste\n",
    "print(\"Dados de teste: \", X_test.shape[0], Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar varios modelos, variando o numero de vizinhos. Para isso, criamos um algoritmo geral para a implementacao do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "def knn_model (n_neighbors):\n",
    "    # Create an instance of K-nearest neighbor classifier\n",
    "    knn_model_n = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Train the classifier with the train data\n",
    "    knn_model_n.fit(X_train,Y_train)\n",
    "\n",
    "    # Compute the prediction over the test data set according to the model\n",
    "    Yhat_n = knn_model_n.predict(X_test)\n",
    "\n",
    "    print('Numero de vizinhos: ', n_neighbors)\n",
    "    print('Valores Preditos: ', Yhat_n)\n",
    "    print ('Valor Predito: ' + str(Yhat_n[-1]), \n",
    "           '; Valor Real: ' + str(Y[-1]))\n",
    "    print('\\n')\n",
    "\n",
    "    return knn_model_n, Yhat_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vizinhos:  1\n",
      "Valores Preditos:  [1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  2\n",
      "Valores Preditos:  [0 0 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  3\n",
      "Valores Preditos:  [1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  4\n",
      "Valores Preditos:  [1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  5\n",
      "Valores Preditos:  [1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  6\n",
      "Valores Preditos:  [1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  7\n",
      "Valores Preditos:  [1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n",
      "Numero de vizinhos:  8\n",
      "Valores Preditos:  [1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1\n",
      " 1 1]\n",
      "Valor Predito: 1 ; Valor Real: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Criacao de varios modelos : \n",
    "\n",
    "# Criacao de uma lista com os modelos e os valores preditos:\n",
    "knn_models = []\n",
    "Yhat_models = []\n",
    "\n",
    "for i in range (8):\n",
    "    knn_model_i, Yhati = knn_model(i+1)\n",
    "    knn_models.append(knn_model_i)\n",
    "    Yhat_models.append(Yhati)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando a qualidade dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um algoritmo geral para a avaliacao dos modelos :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def avaliacao_knn(knn_model_n, n_neighbors, Yhat_n):\n",
    "    print('Numero de vizinhos: ', n_neighbors)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy_train = knn_model_n.score(X_train, Y_train)\n",
    "    print('accuracy in training data:', '{:6.4f}'.format(accuracy_train))\n",
    "    accuracy_test = knn_model_n.score(X_test, Y_test)\n",
    "    print('accuracy in test data:    ', '{:6.4f}'.format(accuracy_test))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    confm = metrics.confusion_matrix(Y_test, Yhat_n)\n",
    "    confmT = confm.T\n",
    "    dfConfusionMatrix = pd.DataFrame(confmT)\n",
    "    dfConfusionMatrix.columns = ['true ' + str(val) for val in outcome_labels]\n",
    "    dfConfusionMatrix.index   = ['pred ' + str(val) for val in outcome_labels]\n",
    "    dfCM = dfConfusionMatrix.iloc[[1,0],[1,0]]  # Positivos primeiro\n",
    "    TP = dfCM.loc['pred 1', 'true 1'] \n",
    "    TN = dfCM.loc['pred 0', 'true 0']\n",
    "    FP = dfCM.loc['pred 1', 'true 0'] # aka false alarm aka Type II error\n",
    "    FN = dfCM.loc['pred 0', 'true 1'] # aka miss aka Type I error\n",
    "    print('true positive (TP): ', TP)\n",
    "    print('true negative (TN): ', TN)\n",
    "    print('false positive (FP):', FP)\n",
    "    print('false negative (FN):', FN)\n",
    "\n",
    "    # Precision and recall\n",
    "    \n",
    "    # precision aka positive predictive value (PPV)\n",
    "    # = what fraction of the cases that my model got are true positive?\n",
    "    precision = TP / (TP + FP)\n",
    "    print('precision   ', '{:7.4f}'.format(precision))\n",
    "    # recall aka sensitivity aka hit rate aka true positive rate (TPR) = TP / P\n",
    "    # = what fraction of the positive cases did my model get?\n",
    "    recall = TP / (TP + FN)\n",
    "    print('recall      ', '{:7.4f}'.format(recall))\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    print('accuracy    ', '{:7.4f}'.format(accuracy))\n",
    "    F1_score = 2 * precision * recall / (precision + recall)\n",
    "    print('F1_score    ', '{:7.4f}'.format(F1_score))\n",
    "    # specificity aka true negative rate (TNR) = TN / N\n",
    "    specificity = TN / (TN + FP)\n",
    "    print('specificity ', '{:7.4f}'.format(specificity))\n",
    "\n",
    "    # Visao geral\n",
    "    # relato de várias métricas de qualidade\n",
    "    print(metrics.classification_report(Y_test, Yhat_n))\n",
    "    print(pd.DataFrame(metrics.classification_report(Y_test, Yhat_n, output_dict = True)))\n",
    "\n",
    "    # support = number of samples of the true response that lie in the class\n",
    "    # avg/total = weighted average (weights are the support values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vizinhos:  1\n",
      "accuracy in training data: 1.0000\n",
      "accuracy in test data:     0.8205\n",
      "true positive (TP):  26\n",
      "true negative (TN):  6\n",
      "false positive (FP): 4\n",
      "false negative (FN): 3\n",
      "precision     0.8667\n",
      "recall        0.8966\n",
      "accuracy      0.8205\n",
      "F1_score      0.8814\n",
      "specificity   0.6000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        10\n",
      "           1       0.87      0.90      0.88        29\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        39\n",
      "   macro avg       0.77      0.75      0.76        39\n",
      "weighted avg       0.82      0.82      0.82        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.631579   0.881356   0.820513   0.756467      0.817311\n",
      "precision   0.666667   0.866667   0.820513   0.766667      0.815385\n",
      "recall      0.600000   0.896552   0.820513   0.748276      0.820513\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  2\n",
      "accuracy in training data: 0.9167\n",
      "accuracy in test data:     0.7949\n",
      "true positive (TP):  24\n",
      "true negative (TN):  7\n",
      "false positive (FP): 3\n",
      "false negative (FN): 5\n",
      "precision     0.8889\n",
      "recall        0.8276\n",
      "accuracy      0.7949\n",
      "F1_score      0.8571\n",
      "specificity   0.7000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64        10\n",
      "           1       0.89      0.83      0.86        29\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        39\n",
      "   macro avg       0.74      0.76      0.75        39\n",
      "weighted avg       0.81      0.79      0.80        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.636364   0.857143   0.794872   0.746753      0.800533\n",
      "precision   0.583333   0.888889   0.794872   0.736111      0.810541\n",
      "recall      0.700000   0.827586   0.794872   0.763793      0.794872\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  3\n",
      "accuracy in training data: 0.8910\n",
      "accuracy in test data:     0.8462\n",
      "true positive (TP):  28\n",
      "true negative (TN):  5\n",
      "false positive (FP): 5\n",
      "false negative (FN): 1\n",
      "precision     0.8485\n",
      "recall        0.9655\n",
      "accuracy      0.8462\n",
      "F1_score      0.9032\n",
      "specificity   0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.50      0.62        10\n",
      "           1       0.85      0.97      0.90        29\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.84      0.73      0.76        39\n",
      "weighted avg       0.84      0.85      0.83        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.625000   0.903226   0.846154   0.764113      0.831886\n",
      "precision   0.833333   0.848485   0.846154   0.840909      0.844600\n",
      "recall      0.500000   0.965517   0.846154   0.732759      0.846154\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  4\n",
      "accuracy in training data: 0.8718\n",
      "accuracy in test data:     0.7949\n",
      "true positive (TP):  25\n",
      "true negative (TN):  6\n",
      "false positive (FP): 4\n",
      "false negative (FN): 4\n",
      "precision     0.8621\n",
      "recall        0.8621\n",
      "accuracy      0.7949\n",
      "F1_score      0.8621\n",
      "specificity   0.6000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        10\n",
      "           1       0.86      0.86      0.86        29\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        39\n",
      "   macro avg       0.73      0.73      0.73        39\n",
      "weighted avg       0.79      0.79      0.79        39\n",
      "\n",
      "              0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.6   0.862069   0.794872   0.731034      0.794872\n",
      "precision   0.6   0.862069   0.794872   0.731034      0.794872\n",
      "recall      0.6   0.862069   0.794872   0.731034      0.794872\n",
      "support    10.0  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  5\n",
      "accuracy in training data: 0.8910\n",
      "accuracy in test data:     0.8205\n",
      "true positive (TP):  27\n",
      "true negative (TN):  5\n",
      "false positive (FP): 5\n",
      "false negative (FN): 2\n",
      "precision     0.8438\n",
      "recall        0.9310\n",
      "accuracy      0.8205\n",
      "F1_score      0.8852\n",
      "specificity   0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        10\n",
      "           1       0.84      0.93      0.89        29\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        39\n",
      "   macro avg       0.78      0.72      0.74        39\n",
      "weighted avg       0.81      0.82      0.81        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.588235   0.885246   0.820513   0.736741      0.809089\n",
      "precision   0.714286   0.843750   0.820513   0.779018      0.810554\n",
      "recall      0.500000   0.931034   0.820513   0.715517      0.820513\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  6\n",
      "accuracy in training data: 0.8846\n",
      "accuracy in test data:     0.8462\n",
      "true positive (TP):  27\n",
      "true negative (TN):  6\n",
      "false positive (FP): 4\n",
      "false negative (FN): 2\n",
      "precision     0.8710\n",
      "recall        0.9310\n",
      "accuracy      0.8462\n",
      "F1_score      0.9000\n",
      "specificity   0.6000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.87      0.93      0.90        29\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.81      0.77      0.78        39\n",
      "weighted avg       0.84      0.85      0.84        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.666667   0.900000   0.846154   0.783333      0.840171\n",
      "precision   0.750000   0.870968   0.846154   0.810484      0.839950\n",
      "recall      0.600000   0.931034   0.846154   0.765517      0.846154\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  7\n",
      "accuracy in training data: 0.8910\n",
      "accuracy in test data:     0.8205\n",
      "true positive (TP):  27\n",
      "true negative (TN):  5\n",
      "false positive (FP): 5\n",
      "false negative (FN): 2\n",
      "precision     0.8438\n",
      "recall        0.9310\n",
      "accuracy      0.8205\n",
      "F1_score      0.8852\n",
      "specificity   0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        10\n",
      "           1       0.84      0.93      0.89        29\n",
      "\n",
      "   micro avg       0.82      0.82      0.82        39\n",
      "   macro avg       0.78      0.72      0.74        39\n",
      "weighted avg       0.81      0.82      0.81        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.588235   0.885246   0.820513   0.736741      0.809089\n",
      "precision   0.714286   0.843750   0.820513   0.779018      0.810554\n",
      "recall      0.500000   0.931034   0.820513   0.715517      0.820513\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  8\n",
      "accuracy in training data: 0.8718\n",
      "accuracy in test data:     0.7949\n",
      "true positive (TP):  26\n",
      "true negative (TN):  5\n",
      "false positive (FP): 5\n",
      "false negative (FN): 3\n",
      "precision     0.8387\n",
      "recall        0.8966\n",
      "accuracy      0.7949\n",
      "F1_score      0.8667\n",
      "specificity   0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.56        10\n",
      "           1       0.84      0.90      0.87        29\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        39\n",
      "   macro avg       0.73      0.70      0.71        39\n",
      "weighted avg       0.78      0.79      0.79        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.555556   0.866667   0.794872   0.711111      0.786895\n",
      "precision   0.625000   0.838710   0.794872   0.731855      0.783912\n",
      "recall      0.500000   0.896552   0.794872   0.698276      0.794872\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(knn_models)):\n",
    "    avaliacao_knn(knn_models[i], i+1, Yhat_models[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os melhores modelos parecem ser o 3 ou o 6, pois tem as melhores acuracias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vizinhos:  3\n",
      "accuracy in training data: 0.8910\n",
      "accuracy in test data:     0.8462\n",
      "true positive (TP):  28\n",
      "true negative (TN):  5\n",
      "false positive (FP): 5\n",
      "false negative (FN): 1\n",
      "precision     0.8485\n",
      "recall        0.9655\n",
      "accuracy      0.8462\n",
      "F1_score      0.9032\n",
      "specificity   0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.50      0.62        10\n",
      "           1       0.85      0.97      0.90        29\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.84      0.73      0.76        39\n",
      "weighted avg       0.84      0.85      0.83        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.625000   0.903226   0.846154   0.764113      0.831886\n",
      "precision   0.833333   0.848485   0.846154   0.840909      0.844600\n",
      "recall      0.500000   0.965517   0.846154   0.732759      0.846154\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n",
      "Numero de vizinhos:  6\n",
      "accuracy in training data: 0.8846\n",
      "accuracy in test data:     0.8462\n",
      "true positive (TP):  27\n",
      "true negative (TN):  6\n",
      "false positive (FP): 4\n",
      "false negative (FN): 2\n",
      "precision     0.8710\n",
      "recall        0.9310\n",
      "accuracy      0.8462\n",
      "F1_score      0.9000\n",
      "specificity   0.6000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.87      0.93      0.90        29\n",
      "\n",
      "   micro avg       0.85      0.85      0.85        39\n",
      "   macro avg       0.81      0.77      0.78        39\n",
      "weighted avg       0.84      0.85      0.84        39\n",
      "\n",
      "                   0          1  micro avg  macro avg  weighted avg\n",
      "f1-score    0.666667   0.900000   0.846154   0.783333      0.840171\n",
      "precision   0.750000   0.870968   0.846154   0.810484      0.839950\n",
      "recall      0.600000   0.931034   0.846154   0.765517      0.846154\n",
      "support    10.000000  29.000000  39.000000  39.000000     39.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avaliacao_knn(knn_models[2], 3, Yhat_models[2])\n",
    "avaliacao_knn(knn_models[5], 6, Yhat_models[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que os três modelos têm a mesma Confusion matrix, e os três modelos sao bons, pois : \n",
    "\n",
    "* A acuracia nos dados de teste é melhor do que todos os outros modelos, mesmo que a acuracia nos dados de treino nao o seja (melhor no modelo 1 ou 2)\n",
    "\n",
    "* O recall é muito alto, o que é bom porque significa que a maioria dos pacientes com PD sao categorizados como PD\n",
    "\n",
    "* O F1_score, usado como avaliador do modelo, é o mais alto também\n",
    "\n",
    "Porém,\n",
    "\n",
    "* A specificity, que mede a precisao na avaliacao de nao PD, nao é tao boa..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber um pouco mais qual é o melhor modelo dentre esses 2 modelos, vamos variar os datasets de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de vizinhos: 3\n",
      "=> Mean accuracy: 0.8461538461538461\n",
      "=> Mean precision: 0.8484848484848485\n",
      "=> Mean recall: 0.9655172413793104\n",
      "=> Mean f1_score: 0.9032258064516129\n",
      "\n",
      "\n",
      "Numero de vizinhos: 6\n",
      "=> Mean accuracy: 0.8461538461538461\n",
      "=> Mean precision: 0.8709677419354839\n",
      "=> Mean recall: 0.9310344827586207\n",
      "=> Mean f1_score: 0.9\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PRC = 0.2\n",
    "knn_good_models = [knn_models[2],knn_models[5]]  ## Modelos 3 e 6\n",
    "for j in range(2):\n",
    "    knn_model = knn_good_models[j]\n",
    "\n",
    "    acc = np.zeros((10,))\n",
    "    precision = np.zeros((10,))\n",
    "    recall = np.zeros((10,))\n",
    "    f1_score = np.zeros((10,))\n",
    "    specificity = np.zeros((10,))\n",
    "    for i in range(10):\n",
    "        dfTrain, dfTest = train_test_split(dfParkinson, test_size=PRC, stratify=dfParkinson[outcome_column], random_state = seed_value)\n",
    "        # convertemos dataframe de features e labels em arrays\n",
    "        X_train = np.array(dfTrain[features])\n",
    "        Y_train = np.array(dfTrain[outcome_column])\n",
    "        \n",
    "        # convertemos dataframe de features e labels em arrays\n",
    "        X_test = np.array(dfTest[features])\n",
    "        Y_test = np.array(dfTest[outcome_column])\n",
    "        \n",
    "        #knn_model = neighbors.KNeighborsClassifier(n_neighbors=8)\n",
    "        knn_model.fit(X_train, Y_train)\n",
    "        Yhat = knn_model.predict(X_test)\n",
    "        acc[i] = metrics.accuracy_score(Y_test, Yhat)\n",
    "        precision[i] = metrics.precision_score(Y_test, Yhat)\n",
    "        recall[i] = metrics.recall_score(Y_test, Yhat)\n",
    "        f1_score[i] = metrics.f1_score(Y_test, Yhat)\n",
    "        \n",
    "    acc.shape=(1,10)\n",
    "    print('Numero de vizinhos: ' + str((j+1)*3))\n",
    "    print('=> Mean accuracy: ' + str(np.mean(acc[0])))\n",
    "    print('=> Mean precision: ' + str(np.mean(precision[0])))\n",
    "    print('=> Mean recall: ' + str(np.mean(recall[0])))\n",
    "    print('=> Mean f1_score: ' + str(np.mean(f1_score[0])))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos sao bastante similares, mas tenderia a dizer que o melhor é o modelo com 3 vizinhos, pois o recall e f1_score sao melhores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
