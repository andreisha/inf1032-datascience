{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipe :\n",
    "    * Jéssica Villar - 1613176\n",
    "    * Fernando Tancini - 1711799\n",
    "    * Andrea Mourelo - 1820000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o dataset1.csv em anexo e desconsiderando a variável target, façam diferentes clusterizações (variando as features, os algoritmos de clustering e suas configurações). Avaliem cada clusterização individualmente e, ao final, façam uma análise comparativa, discutam os resultados e escolham e justifiquem qual foi a melhor clusterização obtida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 0.8)\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import SpectralClustering, AgglomerativeClustering\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import animation\n",
    "\n",
    "%matplotlib notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dataset1.csv'\n",
    "data = pd.read_csv(filename)\n",
    "del data['target']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(data)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns pares de variaveis parecem ter clusters: OU ALGUNS SAO OUTLIERS ??? nseeei\n",
    "* V1 e V4, V1 e V3, V1 e V5, V1 e V6, V1 e V7, V1 e V8, V1 e V9, V1 e V10, V1 e V12\n",
    "* V2 e todos os outros\n",
    "* V3 e V5, V3 e V6, V3 e V7, V3 e V11\n",
    "* V6 e V7, V6 e V8, V6 e V13\n",
    "* V8 e V10, V8 e V13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as colunas do dataframe estão completamente preenchidas e corretamente classificadas ('float','int')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É no mínimo curioso as variáveis 'V1' e 'V2' apresentarem o primeiro quartil e o segundo quartil iguais a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['V1'].hist()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['V1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['V2'].hist()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['V2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a matriz de correlação\n",
    "corr = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando uma matriz de confusão com as correlações entre todas as variáveis\n",
    "f, ax = plt.subplots(figsize=(50,50))\n",
    "cmap = sns.color_palette(\"Spectral\", 10)\n",
    "\n",
    "sns.set(font_scale=2.4)\n",
    "\n",
    "ax = sns.heatmap(corr, cmap=cmap, center=0, annot=True, fmt='.3f',\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_k_means(estimator, name, data, k):\n",
    "    t0 = time()\n",
    "    estimator.fit(data)\n",
    "    print('%-10s, k=%d: sil=%0.4f' % (name, k, metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean',\n",
    "                                      sample_size=sample_size)))\n",
    "    \n",
    "def ModeloClustering(data_in, features, showSNS = True, printIntermediateResults = True):\n",
    "    np.random.seed(1001001)\n",
    "    # standardize data\n",
    "    data_model = scale(data_in)\n",
    "    #\n",
    "    sample_size=len(data_in)\n",
    "    # \n",
    "    best_sil = -999\n",
    "\n",
    "    best_estimator_is_agg = False\n",
    "    best_estimator_is_sc = False\n",
    "    agg_neigbors = 0\n",
    "    \n",
    "    # Varias configuraçoes de KMeans\n",
    "    if (printIntermediateResults) : print('KMeans:')\n",
    "    for init in ['k-means++', 'random']:\n",
    "        for k in range(3,8):\n",
    "            estimator = KMeans(init=init, n_clusters=k, n_init=10, max_iter=100)\n",
    "            estimator.fit(data_model)\n",
    "            sil = metrics.silhouette_score(data_model, estimator.labels_,\n",
    "                                              metric='euclidean',\n",
    "                                              sample_size=sample_size)\n",
    "            if (printIntermediateResults) : print('%-10s, k=%d: sil=%0.4f' % (init, k, sil))\n",
    "            if sil > best_sil:\n",
    "                best_estimator = estimator\n",
    "                best_sil = sil\n",
    "\n",
    "    # Varias configuraçoes de Agglomerative Clustering        \n",
    "    if (printIntermediateResults) : print('\\nAgglomerative Clustering:')\n",
    "    for nClusters in range(2,5):\n",
    "        for nNeigbors in range(1,nClusters+1):\n",
    "            connectivity = kneighbors_graph(data_model, n_neighbors=nNeigbors, include_self=False)\n",
    "            connectivity = 0.5 * (connectivity + connectivity.T)  # make connectivity symmetric\n",
    "            estimator = AgglomerativeClustering(n_clusters= nClusters, linkage=\"average\", affinity=\"cityblock\", connectivity=connectivity)\n",
    "            estimator.fit(data_model)\n",
    "            sil = metrics.silhouette_score(data_model, estimator.labels_,\n",
    "                                                      metric='euclidean',\n",
    "                                                      sample_size=sample_size)\n",
    "            if (printIntermediateResults) : print('clusters=%d, neighbors=%d: sil=%0.4f' % (nClusters, nNeigbors, sil))\n",
    "            if sil > best_sil:\n",
    "                best_estimator = estimator\n",
    "                best_sil = sil\n",
    "                best_estimator_is_agg = True\n",
    "                agg_neigbors = nNeigbors\n",
    "    \n",
    "    # Varias configuraçoes de Spectral Clustering\n",
    "    if (printIntermediateResults) : print('\\nSpectral Clustering:')\n",
    "    for nClusters in range(2,5):\n",
    "        estimator = SpectralClustering(n_clusters=nClusters, affinity='nearest_neighbors', assign_labels='kmeans')\n",
    "        estimator.fit(data_model)\n",
    "        sil = metrics.silhouette_score(data_model, estimator.labels_,\n",
    "                                              metric='euclidean',\n",
    "                                              sample_size=sample_size)\n",
    "        if (printIntermediateResults) : print('clusters=%d, sil=%0.4f' % (nClusters, sil))\n",
    "        if sil > best_sil:\n",
    "            best_estimator = estimator\n",
    "            best_sil = sil\n",
    "            best_estimator_is_sc = True\n",
    "    \n",
    "    if (best_estimator_is_agg):\n",
    "        print('\\nBest estimator silhouette (Agglomerative Clustering): %0.4f with %d clusters and %d neighbors' % (best_sil, best_estimator.n_clusters, agg_neigbors))\n",
    "    elif (best_estimator_is_sc):\n",
    "        print('\\nBest estimator silhouette (Spectral Clustering): %0.4f with %d clusters' % (best_sil, best_estimator.n_clusters))\n",
    "    else :\n",
    "        print('\\nBest estimator silhouette: %0.4f (%d clusters, %s)' % (best_sil, best_estimator.n_clusters, best_estimator.init))\n",
    "    data_in['cluster'] = best_estimator.labels_\n",
    "    if (showSNS == True):\n",
    "        sns.pairplot(data=data_in, vars=features, hue='cluster')\n",
    "        sns.set(font_scale = 1)\n",
    "        plt.figsize=(30,30)\n",
    "    plt.show()\n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = ['V8','V10','V13']\n",
    "data_model_exemplo = data[features]\n",
    "modelo_exemplo = ModeloClustering(data_model_exemplo, features,)\n",
    "#print(data_model_exemplo)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Modelo com silhouette baixa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1\n",
    "### Todas as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = list(data.columns)\n",
    "data_model1 = data.copy()\n",
    "modelo1 = ModeloClustering(data_model1, features, showSNS = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Silhouette ainda pior com todas as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apenas features pouco correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculando a matriz de correlação\n",
    "corr = data.corr()\n",
    "predictors = []\n",
    "for label, content in corr.iteritems():\n",
    "\n",
    "    for element in content:\n",
    "        if ( (element < 0.01) & (element > -0.01)):\n",
    "            predictors.append([label, content[content == element].index[0], element])\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['V2','V11']\n",
    "data_model2 = data.copy()\n",
    "modelo2 = ModeloClustering(data_model2, features, showSNS = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mesmo resultado, que estranho..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - Principal Composant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setPCA(data, nDimensions, columns):\n",
    "    # Precisamos normalizar os dados para usar PCA\n",
    "    data_scaled = scale(data)\n",
    "    pca = PCA(n_components=nDimensions)\n",
    "    principalComponents = pca.fit_transform(data_scaled)\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = columns)\n",
    "    return principalDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDimensions = 2\n",
    "columns = ['Principal Component 1', 'Principal Component 2']\n",
    "pca2 = setPCA(data,nDimensions,columns)\n",
    "pca2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando modelos\n",
    "features = list(pca2.columns)\n",
    "data_model_pca2 = pca2.copy()\n",
    "modelo_pca2 = ModeloClustering(data_model_pca2, features, showSNS = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Vemos que o silhouette melhorou bastante graças ao PCA\n",
    "\n",
    "Vamos visualizar os resultados em 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "plt.scatter(x=data_model_pca2['Principal Component 1'], y=data_model_pca2['Principal Component 2'], marker='.', c=modelo_pca2.labels_, cmap='tab20b', s=10, alpha=1.0)\n",
    "ax.set_xlabel('PC1', fontsize = 16)\n",
    "ax.set_ylabel('PC2', fontsize = 16)\n",
    "ax.set_title('PCA com 2 dimensoes', fontsize = 18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "print(data_model_pca2.cluster.value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDimensions = 3\n",
    "columns = ['Principal Component 1', 'Principal Component 2', 'Principal Component 3']\n",
    "pca3 = setPCA(data,nDimensions,columns)\n",
    "# Aplicando modelos\n",
    "features = list(pca3.columns)\n",
    "data_model_pca3 = pca3.copy()\n",
    "modelo_pca3 = ModeloClustering(data_model_pca3, features, showSNS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(data_model_pca3['Principal Component 1'],data_model_pca3['Principal Component 2'],data_model_pca3['Principal Component 3'],c=modelo_pca3.labels_, cmap='tab20b', s=10, alpha=0.5)\n",
    "ax.set_xlabel('PC1', fontsize = 14)\n",
    "ax.set_ylabel('PC2', fontsize = 14)\n",
    "ax.set_zlabel('PC3', fontsize = 14)\n",
    "ax.set_title('PCA com 3 dimensoes', fontsize = 16)\n",
    "ax.tick_params(axis='both',labelsize=10)\n",
    "print(data_model_pca3.cluster.value_counts())\n",
    "ax.view_init(30)\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### de 4 até 10 dimensões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerações finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['PC 1', 'PC 2', 'PC 3']\n",
    "for i in range(4,11):\n",
    "    nDimensions = i\n",
    "    column = 'PC ' + str(i)\n",
    "    columns.append(column)\n",
    "    pca_i = setPCA(data,nDimensions,columns)\n",
    "    # Aplicando modelos\n",
    "    features = list(pca_i.columns)\n",
    "    data_model_pca_i = pca_i.copy()\n",
    "    print('nDimensions = ', nDimensions)\n",
    "    modelo_pca_i = ModeloClustering(data_model_pca_i, features, showSNS = False, printIntermediateResults = False)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parece que ao usar PCA com 7 dimensoes obstemos a melhor silhouette - 0.6982"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDS - Multidimensional Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAMP - Local Affine Multidimensional Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analise comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
