{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION OF PARKISON'S DISEASE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipe :\n",
    "    * Jéssica Villar - 1613176\n",
    "    * Fernando Tancini - 1711799\n",
    "    * Andrea Mourelo - 1820000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia deste trabalho é de encontrar um modelo que permita prever se um paciente dado vai ter Parkinson ou nao.\n",
    "\n",
    "Para isso, vamos usar o dataset 'parkinsons.data' que se encontra no link: https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/\n",
    "\n",
    "Nesse link encontramos a descriçao do dataset: 'This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD. '\n",
    "\n",
    "\n",
    "Ao longo deste trabalho, vamos tentar encontrar um modelo preditivo variando:\n",
    "* Primeiro, o número de linhas usadas desse dataset: o dataset inteiro ou um dataset equilibrado\n",
    "* Depois, o número e tipo de features usadas no modelo: todas as features, a metade ou as mais significativas, etc.\n",
    "* Também, nosso trabalho vai variar os modelos usados: kNN, SVM ou Decision Trees\n",
    "* Finalmente, variaremos as configurações dos algoritmos: kNN será usado com o parâmetro de vizinhos entre 1 e 6 e a altura dos decision trees variará entre 2 e 7\n",
    "\n",
    "\n",
    "Para fazer a análise dos resultados, vamos considerar que o melhor modelo é o que tem uma acurácia:\n",
    "* média o mais alta possível\n",
    "* tentando que a mediana seja também elevada\n",
    "* e que o primeiro quartil esteja acima de 0,8\n",
    "\n",
    "Além disso, gostaríamos também de ter um recall o mais elevado possível, pois nesse caso médico, os pacientes considerados 'False Negatives' são de extrema importância e teriam que ser quase nulos no melhor modelo.\n",
    "\n",
    "Para fazer este trabalho acadêmico e para obter sempre os mesmos resultados, vamos definir uma seed e usá-la ao longo do nosso trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotecas e funções de visualização e ML\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('font', family='Arial')\n",
    "plt.rc('xtick', labelsize=20) \n",
    "plt.rc('ytick', labelsize=20) \n",
    "plt.rc('font', size=20) \n",
    "plt.rc('figure', figsize = (12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função usada para o set up da seed a cada função, pois se não não funcionava\n",
    "def set_seed():\n",
    "    # Set a seed value: \n",
    "    seed_value = 1001004  \n",
    "    # 1. Set PYTHONHASHSEED environment variable at a fixed value: \n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "    # 2. Set python built-in pseudo-random generator at a fixed value:\n",
    "    import random\n",
    "    random.seed(seed_value) \n",
    "    # 3. Set numpy pseudo-random generator at a fixed value:\n",
    "    np.random.seed(seed_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson's Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damos uma olhada nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'parkinsons.data'\n",
    "dfParkinson = pd.read_csv(filename)\n",
    "dfParkinson.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_column = 'status'\n",
    "# status: 0: healthy, 1: Parkinson's\n",
    "outcome_labels = {0: 'healthy', 1:'Parkinson`s'}\n",
    "label_counts = np.bincount(dfParkinson.status)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que temos mais dados de pacientes com Parkinsons do que sem. Por enquanto, vamos usar todos os dados para análise mais no final do trabalho vamos somente pegar um dataset equilibrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções usadas ao longo do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos uma função que, a partir de um df, uma lista e um número de features, uma porcentagem PRC,\n",
    "# um inteiro numModelos, e uns titulos,\n",
    "# cria varios modelos (13 modelos variando parâmetros de kNN,SVM e Decision Trees) com PRC % de dados de teste\n",
    "# com cada modelo sendo testado numModelos vezes\n",
    "# retorna as acuracias, precisions, recalls e f1_scores de cada modelo\n",
    "# e plota os BoxPlot dos diferentes modelos\n",
    "\n",
    "def modelos(df, features, nFeatures, PRC, numModelos, titles):\n",
    "    # Reusamos a função de seed, se não não funciona...\n",
    "    seed_value = 1001004  \n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "    import random\n",
    "    random.seed(seed_value) \n",
    "    np.random.seed(seed_value) \n",
    "    \n",
    "    # Vamos a guardar as acurácias, precision, recall e f1_score de todos os modelos\n",
    "    # Essas listas terão nFeatures objetos cada uma\n",
    "    acuracias = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    # Aplicamos 13 modelos a esses nFeatures tipos de dados\n",
    "    for j in range(nFeatures):\n",
    "        # convertemos feature dataframe e label series para arrays\n",
    "        X = np.array(df[features[j]]) # X = array de dados dos pacientes\n",
    "        Y = np.array(df[outcome_column]) # Y = outcome \"status\" dos pacientes\n",
    "\n",
    "        # vamos chamar essa loop numModelos vezes, criando 13 models a cada vez\n",
    "        acc_r=np.zeros((numModelos,13))\n",
    "        precision_r=np.zeros((numModelos,13))\n",
    "        recall_r=np.zeros((numModelos,13))\n",
    "        f1_score_r=np.zeros((numModelos,13))\n",
    "\n",
    "        # numModelos iterações\n",
    "        for i in range(numModelos):\n",
    "            # Controlamos que os valores sejam sempre os mesmos (com uma seed),\n",
    "            # Mas cada iteração deve ter dados diferentes para nao obter sempre a mesma accuracy\n",
    "            seed = seed_value + i*1200 \n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=PRC,random_state = seed)\n",
    "\n",
    "            # configuramos 13 tipos de modelos\n",
    "            nn1 = neighbors.KNeighborsClassifier(n_neighbors=1) # kNN com 1 vizinho\n",
    "            nn2 = neighbors.KNeighborsClassifier(n_neighbors=2) # kNN com 2 vizinhos\n",
    "            nn3 = neighbors.KNeighborsClassifier(n_neighbors=3) # kNN com 3 vizinhos\n",
    "            nn4 = neighbors.KNeighborsClassifier(n_neighbors=4) # kNN com 4 vizinhos\n",
    "            nn5 = neighbors.KNeighborsClassifier(n_neighbors=5) # kNN com 5 vizinhos\n",
    "            nn6 = neighbors.KNeighborsClassifier(n_neighbors=6) # kNN com 6 vizinhos\n",
    "            svc = svm.SVC(gamma='auto') # SVM\n",
    "            dt2 = tree.DecisionTreeClassifier(max_depth = 2) # Decision Tree de altura 2\n",
    "            dt3 = tree.DecisionTreeClassifier(max_depth = 3) # Decision Tree de altura 3\n",
    "            dt4 = tree.DecisionTreeClassifier(max_depth = 4) # Decision Tree de altura 4\n",
    "            dt5 = tree.DecisionTreeClassifier(max_depth = 5) # Decision Tree de altura 5\n",
    "            dt6 = tree.DecisionTreeClassifier(max_depth = 6) # Decision Tree de altura 6\n",
    "            dt7 = tree.DecisionTreeClassifier(max_depth = 7) # Decision Tree de altura 7\n",
    "\n",
    "            # treinamos cada modelo\n",
    "            nn1.fit(X_train,Y_train)\n",
    "            nn2.fit(X_train,Y_train)\n",
    "            nn3.fit(X_train,Y_train)\n",
    "            nn4.fit(X_train,Y_train)\n",
    "            nn5.fit(X_train,Y_train)\n",
    "            nn6.fit(X_train,Y_train)\n",
    "            svc.fit(X_train,Y_train)\n",
    "            dt2.fit(X_train,Y_train)\n",
    "            dt3.fit(X_train,Y_train)\n",
    "            dt4.fit(X_train,Y_train)\n",
    "            dt5.fit(X_train,Y_train)\n",
    "            dt6.fit(X_train,Y_train)\n",
    "            dt7.fit(X_train,Y_train)\n",
    "\n",
    "            # testamos cada modelo\n",
    "            Yhat_nn1=nn1.predict(X_test)\n",
    "            Yhat_nn2=nn2.predict(X_test)\n",
    "            Yhat_nn3=nn3.predict(X_test)\n",
    "            Yhat_nn4=nn4.predict(X_test)\n",
    "            Yhat_nn5=nn5.predict(X_test)\n",
    "            Yhat_nn6=nn6.predict(X_test)\n",
    "            Yhat_svc=svc.predict(X_test)\n",
    "            Yhat_dt2=dt2.predict(X_test)\n",
    "            Yhat_dt3=dt3.predict(X_test)\n",
    "            Yhat_dt4=dt4.predict(X_test)\n",
    "            Yhat_dt5=dt5.predict(X_test)\n",
    "            Yhat_dt6=dt6.predict(X_test)\n",
    "            Yhat_dt7=dt7.predict(X_test)\n",
    "\n",
    "            # acurácia de cada modelo nessa iteração\n",
    "            acc_r[i][0] = metrics.accuracy_score(Yhat_nn1, Y_test)\n",
    "            acc_r[i][1] = metrics.accuracy_score(Yhat_nn2, Y_test)\n",
    "            acc_r[i][2] = metrics.accuracy_score(Yhat_nn3, Y_test)\n",
    "            acc_r[i][3] = metrics.accuracy_score(Yhat_nn4, Y_test)\n",
    "            acc_r[i][4] = metrics.accuracy_score(Yhat_nn5, Y_test)\n",
    "            acc_r[i][5] = metrics.accuracy_score(Yhat_nn6, Y_test)\n",
    "            acc_r[i][6] = metrics.accuracy_score(Yhat_svc, Y_test)\n",
    "            acc_r[i][7] = metrics.accuracy_score(Yhat_dt2, Y_test)\n",
    "            acc_r[i][8] = metrics.accuracy_score(Yhat_dt3, Y_test)\n",
    "            acc_r[i][9] = metrics.accuracy_score(Yhat_dt4, Y_test)\n",
    "            acc_r[i][10] = metrics.accuracy_score(Yhat_dt5, Y_test)\n",
    "            acc_r[i][11] = metrics.accuracy_score(Yhat_dt6, Y_test)\n",
    "            acc_r[i][12] = metrics.accuracy_score(Yhat_dt7, Y_test)\n",
    "\n",
    "            # precision de cada modelo nessa iteração\n",
    "            precision_r[i][0] = metrics.precision_score(Yhat_nn1, Y_test)\n",
    "            precision_r[i][1] = metrics.precision_score(Yhat_nn2, Y_test)\n",
    "            precision_r[i][2] = metrics.precision_score(Yhat_nn3, Y_test)\n",
    "            precision_r[i][3] = metrics.precision_score(Yhat_nn4, Y_test)\n",
    "            precision_r[i][4] = metrics.precision_score(Yhat_nn5, Y_test)\n",
    "            precision_r[i][5] = metrics.precision_score(Yhat_nn6, Y_test)\n",
    "            precision_r[i][6] = metrics.precision_score(Yhat_svc, Y_test)\n",
    "            precision_r[i][7] = metrics.precision_score(Yhat_dt2, Y_test)\n",
    "            precision_r[i][8] = metrics.precision_score(Yhat_dt3, Y_test)\n",
    "            precision_r[i][9] = metrics.precision_score(Yhat_dt4, Y_test)\n",
    "            precision_r[i][10] = metrics.precision_score(Yhat_dt5, Y_test)\n",
    "            precision_r[i][11] = metrics.precision_score(Yhat_dt6, Y_test)\n",
    "            precision_r[i][12] = metrics.precision_score(Yhat_dt7, Y_test)\n",
    "\n",
    "            # recall de cada modelo nessa iteração\n",
    "            recall_r[i][0] = metrics.recall_score(Yhat_nn1, Y_test)\n",
    "            recall_r[i][1] = metrics.recall_score(Yhat_nn2, Y_test)\n",
    "            recall_r[i][2] = metrics.recall_score(Yhat_nn3, Y_test)\n",
    "            recall_r[i][3] = metrics.recall_score(Yhat_nn4, Y_test)\n",
    "            recall_r[i][4] = metrics.recall_score(Yhat_nn5, Y_test)\n",
    "            recall_r[i][5] = metrics.recall_score(Yhat_nn6, Y_test)\n",
    "            recall_r[i][6] = metrics.recall_score(Yhat_svc, Y_test)\n",
    "            recall_r[i][7] = metrics.recall_score(Yhat_dt2, Y_test)\n",
    "            recall_r[i][8] = metrics.recall_score(Yhat_dt3, Y_test)\n",
    "            recall_r[i][9] = metrics.recall_score(Yhat_dt4, Y_test)\n",
    "            recall_r[i][10] = metrics.recall_score(Yhat_dt5, Y_test)\n",
    "            recall_r[i][11] = metrics.recall_score(Yhat_dt6, Y_test)\n",
    "            recall_r[i][12] = metrics.recall_score(Yhat_dt7, Y_test)\n",
    "\n",
    "            # f1_score de cada modelo nessa iteração\n",
    "            f1_score_r[i][0] = metrics.f1_score(Yhat_nn1, Y_test)\n",
    "            f1_score_r[i][1] = metrics.f1_score(Yhat_nn2, Y_test)\n",
    "            f1_score_r[i][2] = metrics.f1_score(Yhat_nn3, Y_test)\n",
    "            f1_score_r[i][3] = metrics.f1_score(Yhat_nn4, Y_test)\n",
    "            f1_score_r[i][4] = metrics.f1_score(Yhat_nn5, Y_test)\n",
    "            f1_score_r[i][5] = metrics.f1_score(Yhat_nn6, Y_test)\n",
    "            f1_score_r[i][6] = metrics.f1_score(Yhat_svc, Y_test)\n",
    "            f1_score_r[i][7] = metrics.f1_score(Yhat_dt2, Y_test)\n",
    "            f1_score_r[i][8] = metrics.f1_score(Yhat_dt3, Y_test)\n",
    "            f1_score_r[i][9] = metrics.f1_score(Yhat_dt4, Y_test)\n",
    "            f1_score_r[i][10] = metrics.f1_score(Yhat_dt5, Y_test)\n",
    "            f1_score_r[i][11] = metrics.f1_score(Yhat_dt6, Y_test)\n",
    "            f1_score_r[i][12] = metrics.f1_score(Yhat_dt7, Y_test)\n",
    "\n",
    "        acuracias.append(acc_r)\n",
    "        precisions.append(precision_r)\n",
    "        recalls.append(recall_r)\n",
    "        f1_scores.append(f1_score_r)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(15,6))\n",
    "        plt.boxplot(acc_r)\n",
    "        for i in range(13):\n",
    "            xderiv = (i+1) * np.ones(acc_r[:,i].shape) + (np.random.rand(10,)-0.5) * 0.1\n",
    "            plt.plot(xderiv, acc_r[:,i], 'ro', alpha=0.3)\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticklabels(['1-NN', '2-NN','3-NN', '4-NN','5-NN', '6-NN','SVM',\n",
    "                            'DT2','DT3','DT4','DT5','DT6','DT7'])\n",
    "        plt.ylabel('Acuracia')\n",
    "        ax.set_title(titles[j])\n",
    "        plt.show()\n",
    "        #plt.savefig('figs/error_ms_1.png',dpi=300, bbox_inches='tight')    return acuracias, precisions, recalls, f1_scores\n",
    "    \n",
    "    return acuracias, precisions, recalls, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos uma função que, depois de executar a função anterior, vai plotar um heatmap\n",
    "# A ideia é que num_modelo é um inteiro entre 0 e numFeatures\n",
    "\n",
    "def analise_modelos_obtidos(num_modelo, titulo):\n",
    "    models = ['1-NN', '2-NN','3-NN', '4-NN','5-NN', '6-NN','SVM','DT2','DT3','DT4','DT5','DT6','DT7']\n",
    "    \n",
    "    # Usamos os arrays retornados pela função anterior\n",
    "    acuracias_num = pd.DataFrame(acuracias[num_modelo])\n",
    "    precisions_num = pd.DataFrame(precisions[num_modelo])\n",
    "    recalls_num = pd.DataFrame(recalls[num_modelo])\n",
    "    f1_scores_num = pd.DataFrame(f1_scores[num_modelo])\n",
    "    acuracias_num.columns, precisions_num.columns = models, models\n",
    "    recalls_num.columns, f1_scores_num.columns = models, models\n",
    "    \n",
    "    # Ver um pouco mais tarde no projeto um exemplo para visualizar esse df análise\n",
    "    analise = pd.DataFrame(acuracias_num.mean(), columns = ['Accuracy'])\n",
    "    analise['Precision'] = pd.DataFrame(precisions_num.mean())\n",
    "    analise['Recall'] = pd.DataFrame(recalls_num.mean())\n",
    "    analise['F1_Score'] = pd.DataFrame(f1_scores_num.mean())\n",
    "    analise = analise.T\n",
    "    \n",
    "    # Plot\n",
    "    sns.set(font_scale=1.2)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title(titulo)\n",
    "    vMeio = (analise[:1].min().min() + analise[:1].max().max())/2  # Para as cores serem centradas no valor medio das accuracies\n",
    "    sns.heatmap(analise, annot=True, square=True, cbar=False, fmt=\".3f\", linewidths=0.95, cmap='Greens', vmin = vMeio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Selecionamos todas as colunas como features, menos 'name' e 'status', essa última sendo nosso target.\n",
    "features_all = [col for col in dfParkinson.columns if col not in ['name', 'status']]\n",
    "\n",
    "# Selecionamos aleatoriamente metade das colunas\n",
    "features_half = []\n",
    "features_other_half = []\n",
    "num_columns = len(features_all)\n",
    "random_columns = sorted(random.sample(range(0, num_columns), int(num_columns/2)))\n",
    "for i in range(len(features_all)):\n",
    "    if (i in random_columns): \n",
    "        features_half.append(features_all[i])\n",
    "    else : \n",
    "        features_other_half.append(features_all[i])\n",
    "\n",
    "print('As primeiras 11 features, escolhidas aleatoriamente, são:')\n",
    "print(features_half)\n",
    "print('\\n' + 'As outras 11 features são:')\n",
    "print(features_other_half)\n",
    "\n",
    "# Chamamos nossa função de modelo\n",
    "features = [features_all, features_half, features_other_half]\n",
    "PRC = 0.2  # 20% de teste\n",
    "titles = [\"Todas as features no modelo\",\"Metade das features no modelo\",\"Outra metade das features no modelo\"]\n",
    "acuracias, precisions, recalls, f1_scores = modelos(dfParkinson,features,len(features),PRC, 10, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa a se observar é a grande variação dos resultados dos modelos ao selecionar diferentes features. Efetivamente, as distribuições em geral variam muito, mas as distribuições para um mesmo tipo de modelo também.\n",
    "\n",
    "Além disso, podemos dizer que:\n",
    "\n",
    "* Quando todas as features são consideradas, o modelo com a melhor acurácia em mediana é o Decision Tree com altura 5. Além disso, o primeiro quartil é quase o mais elevado, o que mostra que a distribuição é bem homogênea.\n",
    "\n",
    "* Enquanto isso, quando as primeiras 11 features são escolhidas aleatoriamente, o modelo com melhor acurácia em mediana segue sendo o DT5. Nesse caso, o segundo e terceiro quartil são iguais, o que mostra que a distribuição é ainda mais homogênea, pois temos muitas acurácias concentradas em 0.9 (quase). Também, observamos que a acurácia mínima desse modelo é menor do que a acurácia mínima do DT5 no caso anterior, mas a acurácia do primeiro quartil é maior.\n",
    "\n",
    "* Ao escolher outras 11 features, o modelo com melhor acurácia em mediana passa a ser o DT com altura 7. Nesse caso, a acurácia mediana é maior do que nos outros dois \"melhores\" modelos anteriores (0.92 ao invés de 0.9 ou menos), mas a distribuição é muito mais heterogênea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das médias das accuracy, precision, recall e f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar as matrizes obtidas por modelo para entender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = ['1-NN', '2-NN','3-NN', '4-NN','5-NN', '6-NN','SVM','DT2','DT3','DT4','DT5','DT6','DT7']\n",
    "\n",
    "acuracias_all = pd.DataFrame(acuracias[0])\n",
    "precisions_all = pd.DataFrame(precisions[0])\n",
    "recalls_all = pd.DataFrame(recalls[0])\n",
    "f1_scores_all = pd.DataFrame(f1_scores[0])\n",
    "acuracias_all.columns, precisions_all.columns = models, models\n",
    "recalls_all.columns, f1_scores_all.columns = models, models\n",
    "\n",
    "# Só para entender, print de acuracias_all:\n",
    "acuracias_all\n",
    "# As colunas representam os modelos e as linhas as iterações feitas (com dados de testes diferentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só pra entender de onde vem o heatmap depois:\n",
    "analise = pd.DataFrame(acuracias_all.mean(), columns = ['Accuracy'])\n",
    "analise['Precision'] = pd.DataFrame(precisions_all.mean())\n",
    "analise['Recall'] = pd.DataFrame(recalls_all.mean())\n",
    "analise['F1_Score'] = pd.DataFrame(f1_scores_all.mean())\n",
    "analise = analise.T\n",
    "analise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora mostrar os resultados (todo sao médias das 10 iterações de cada modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analise_modelos_obtidos(0,'Analise dos modelos - Todas as features')\n",
    "analise_modelos_obtidos(1,'Analise dos modelos - Uma metade das features')\n",
    "analise_modelos_obtidos(2,'Analise dos modelos - Outra metade das features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa que podemos observar é que, nos 3 casos, as maiores acurácias médias são obtidas com os Decision Trees. A melhor acurácia média é obtida com o Decision Tree de altura 7 e a segunda metade das features.\n",
    "\n",
    "Porém, a maior Precision é obtida com o modelo SVM e a primeira metade das features ou todas as features. Esse resultado é igual a 1, o que pode ser considerado como overfitting pois é bastante raro. Esse overfitting faz sentido se pensamos que a grande maioria dos nossos dados são pacientes com valor 'true' (tendo Parkinson).\n",
    "\n",
    "Como foi dito acima, nesse estudo especificamente, o recall é muito importante, pois quanto menos FN, mais o recall melhora. Observamos que o melhor recall é obtido com o modelo 2-NN usando todas as features (0.930), mas o recall do Decision Tree de altura 7 com a segunda metade das features já é bem bom (0.907).\n",
    "\n",
    "Finalmente, o F1_score, medida de avaliação do modelo, é maior no modelo Decision Tree de altura 7 com a segunda metade das features (0.922)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em conclusão, parece que esse modelo Decision Tree de altura 7 com a segunda metade das features (['MDVP:Fo(Hz)', 'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP', 'MDVP:Shimmer', 'MDVP:APQ', 'Shimmer:DDA', 'RPDE', 'DFA', 'spread2']) seria o melhor modelo se tivermos que usar os valores médios.\n",
    "\n",
    "Porém, o Decision Tree de altura 5 com a primeira metade das features (['MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5', 'NHR', 'HNR', 'spread1', 'D2', 'PPE'])parece ter uma melhor distribuição das acurácias e uns bons valores para f1_score e recall (> 0.9). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos tentar observar quais são as variáveis que tem maior correlação com o 'status' e criar novos modelos para conferer se ao escolher melhores features, teremos melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da correlação entre features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qual a correlação do 'status' (variável a ser predita) com as outras variáveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Calculando a matriz de correlação\n",
    "corr = dfParkinson.corr()\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Analisando as correlações de 'status' com as outras variáveis\n",
    "c = corr['status'].drop('status')\n",
    "c.plot(kind='barh', title = 'Correlação com status', figsize = (14,10), color = '#5499C7', grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "# Montando uma matriz de confusão com as correlações entre todas as variáveis\n",
    "f, ax = plt.subplots(figsize=(50,50))\n",
    "cmap = sns.color_palette(\"Spectral\", 10)\n",
    "\n",
    "sns.set(font_scale=2.4)\n",
    "\n",
    "ax = sns.heatmap(corr, cmap=cmap, center=0, annot=True, fmt='.3f',\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que esse método corr() nos informa que as colunas que estão mais correlacionadas com o 'status' são:\n",
    "\n",
    "* Correlação positiva : spread1, spread2 e PPE\n",
    "* Correlação negativa : MDVP:Fo(Hz), MDVP:Flo(Hz) e HNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "X = dfParkinson.drop('status',axis=1).iloc[:,1:]\n",
    "y = dfParkinson['status']\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)\n",
    "\n",
    "# plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(11).plot(kind='barh', title = 'Feature importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa classificação das features pelo ExtraTreesClassifier nos permite ver quais são as 11 features mais correlacionadas, segundo esse modelo, como o 'status'. Encontramos todas as features que o modelo anterior nos deu, mas com rankings diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, vamos fazer vários modelos tendo em conta esses resultados.\n",
    "\n",
    "* O \"Modelo com features de correlação positiva\" vai usar todas as features com coeficiente positivo (no método corr())\n",
    "* O \"Modelo com as features de correlação negativa\" vai usar todas as features com coeficiente negativo (no método corr())\n",
    "* O \"Modelo com features de maior correlação\" vai usar todas as features com coeficiente alto (no método ExtraTreesClassifier())\n",
    "* O \"Modelo com features de maior correlação positiva\" vai usar todas as features com coeficiente alto (no método ExtraTreesClassifier()), mas que são positivas no método corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_seed()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Selecionamos as colunas \n",
    "features_positive = [col for col in dfParkinson.columns if col not in ['name', 'status','HNR','MDVP:Fo(Hz)','MDVP:Flo(Hz)','MDVP:Fhi(Hz)']]\n",
    "features_negative = [col for col in dfParkinson.columns if col in ['HNR','MDVP:Fo(Hz)','MDVP:Flo(Hz)','MDVP:Fhi(Hz)']]\n",
    "features_max = [col for col in dfParkinson.columns if col in ['spread1','MDVP:Fo(Hz)','PPE','MDVP:RAP',\n",
    "                                                              'MDVP:Fhi(Hz)','spread2','MDVP:Jitter(%)',\n",
    "                                                              'MDVP:Shimer','MDVP:Flo(Hz)','D2','DFA']]\n",
    "features_max_onlypositive = [col for col in dfParkinson.columns if col in ['spread1','PPE','MDVP:RAP',\n",
    "                                                              'spread2','MDVP:Jitter(%)',\n",
    "                                                              'MDVP:Shimer','D2','DFA']]\n",
    "# Chamamos nossa função com os parâmetros\n",
    "features = [features_positive,features_negative,features_max,features_max_onlypositive]\n",
    "PRC = 0.2\n",
    "titles = [\"Modelo com as features de correlação positiva\",\"Modelo com as features de correlação negativa\",\n",
    "         \"Modelo com as features de maior correlação\", \"Modelo com as features de maior correlação positiva\"]\n",
    "acuracias, precisions, recalls, f1_scores = modelos(dfParkinson,features,len(features),PRC, 10, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De novo observamos as grandes diferenças que existem entre os diferentes modelos ao ter features diferentes.\n",
    "\n",
    "Além disso, podemos dizer que:\n",
    "\n",
    "* Quando usamos todas as features com coeficiente positivo (no método corr()), o modelo tendo a melhor acurácia em mediana é o kNN com 6 vizinhos. Porém, a distribuição é bastante heterogênea, tendo alguns valores de acurácia abaixo de 0.8.\n",
    "\n",
    "* Quando usamos todas as features com coeficiente negativo (no metodo corr()), o modelo tendo a melhor acuracia em mediana é o kNN com 1 vizinho. Porém, a distribuiçao é bastante heterogênea, tendo alguns valores por baixo de 0.75 de acuracia.\n",
    "\n",
    "* Ao usar as features com coeficiente alto dadas pelo no método ExtraTreesClassifier(), obtemos que todos os modelos de Decision Trees têm acurácias medianas superiores ou iguais a 0.85. Para os DT com alturas superiores ou iguais a 3, temos acurácias medianas perto de 0.9, o que é muito bom, mas todos têm outliers inferiores a 0.8. O melhor compromisso parece ser o DT de altura 2, pois tem bons resultados e são bem homogêneos. \n",
    "\n",
    "* Finalmente, ao usar todas as features com coeficiente alto (no método ExtraTreesClassifier()), mas que são positivos no método corr(), obtemos modelos bons. O que têm a melhor acurácia mediana é o kNN com 6 vizinhos. A distribuição parece boa, pois é homogênea e com todos os resultados superiores a 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos modelos obtidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analise_modelos_obtidos(num_modelo, titulo):\n",
    "    models = ['1-NN', '2-NN','3-NN', '4-NN','5-NN', '6-NN','SVM','DT2','DT3','DT4','DT5','DT6','DT7']\n",
    "\n",
    "    acuracias_num = pd.DataFrame(acuracias[num_modelo])\n",
    "    precisions_num = pd.DataFrame(precisions[num_modelo])\n",
    "    recalls_num = pd.DataFrame(recalls[num_modelo])\n",
    "    f1_scores_num = pd.DataFrame(f1_scores[num_modelo])\n",
    "    acuracias_num.columns, precisions_num.columns = models, models\n",
    "    recalls_num.columns, f1_scores_num.columns = models, models\n",
    "    \n",
    "    analise = pd.DataFrame(acuracias_num.mean(), columns = ['Accuracy'])\n",
    "    analise['Precision'] = pd.DataFrame(precisions_num.mean())\n",
    "    analise['Recall'] = pd.DataFrame(recalls_num.mean())\n",
    "    analise['F1_Score'] = pd.DataFrame(f1_scores_num.mean())\n",
    "    analise = analise.T\n",
    "    sns.set(font_scale=1.2)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.title(titulo)\n",
    "    vMeio = (analise[:1].min().min() + analise[:1].max().max())/2  # Para as cores serem centradas no valor medio das accuracies\n",
    "    sns.heatmap(analise, annot=True, square=True, cbar=False, fmt=\".3f\", linewidths=0.95, cmap='Greens', vmin = vMeio)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analise_modelos_obtidos(0,'Análise dos modelos - Features com correlação positiva')\n",
    "analise_modelos_obtidos(1,'Análise dos modelos - Features com correlação negativa')\n",
    "analise_modelos_obtidos(2,'Análise dos modelos - Features com maior correlação')\n",
    "analise_modelos_obtidos(3,'Análise dos modelos - Features com maior correlação positiva')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa que podemos observar é que as maiores acurácias médias são obtidas com:\n",
    "* O kNN com 3 vizinhos para as features com correlação positiva\n",
    "* O kNN com 1 vizinho para as features com correlação negativa\n",
    "* O DT de altura 3 para as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier().\n",
    "* O kNN com 5 vizinhos para as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier() tendo coeficientes positivos no corr().\n",
    "\n",
    "A melhor acurácia média (0.895) é obtida com o Decision Tree de altura 3 e as features com maiores coeficientes obtidos pelo metodo ExtraTreesClassifier(). Essa acurácia média é superior à maior média obtida na primeira parte do trabalho (0.879).\n",
    "\n",
    "De novo, as maiores precisions são obtidas com o modelo SVM e isso segue fazendo sentido se pensamos que a grande maioria dos nossos dados são pacientes com valor 'true' (tendo Parkinson).\n",
    "\n",
    "Observamos que o melhor recall é obtido com o modelo 2-NN usando as features com correlação positiva dadas pelo método corr() (0.937), mas os recall do Decision Tree de altura 3 e as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier() já é bastante bom (0.907).\n",
    "\n",
    "Finalmente, o F1_score, medida de avaliação do modelo, é maior no modelo Decision Tree de altura 3 e as features com maiores coeficientes obtidos pelo metodo ExtraTreesClassifier() (0.932)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em conclusão, parece que esse modelo Decision Tree de altura 3 e as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier() seria o melhor modelo se tivermos que usar os valores médios.\n",
    "\n",
    "Porém, esse modelo tem uns outliers bem baixos, então o modelo Decision Tree de altura 6 e as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier() poderia ser um bom compromisso pois é mais homogêneo, tem outliers mais perto da mediana e têm uma acurácia média maior do que o \"melhor\" modelo da parte anterior do trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos com DataSet Equilibrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ver o que acontece se criamos modelos com um dataset equilibrado (48 sem Parkinsons e 48 com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "noParkinson = dfParkinson[dfParkinson['status'] == 0] # linhas com status = 0\n",
    "Parkinson = dfParkinson[dfParkinson['status'] == 1] # linhas com status = 1\n",
    "\n",
    "rowsParkinson = np.random.choice(Parkinson.index.values, 48) # Escolhemos 48 linhas com Parkinson aleatoriamente\n",
    "rowsNoParkinson = noParkinson.index.values \n",
    "rows = np.concatenate([rowsParkinson, rowsNoParkinson])\n",
    "\n",
    "dfParkinsonEquilibrate = dfParkinson.iloc[rows] # Temos 96 (48*2) linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aplicamos a função de modelos\n",
    "set_seed()\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "# Selecionamos as colunas \n",
    "features_positive = [col for col in dfParkinson.columns if col not in ['name', 'status','HNR','MDVP:Fo(Hz)','MDVP:Flo(Hz)','MDVP:Fhi(Hz)']]\n",
    "features_negative = [col for col in dfParkinson.columns if col in ['HNR','MDVP:Fo(Hz)','MDVP:Flo(Hz)','MDVP:Fhi(Hz)']]\n",
    "features_max = [col for col in dfParkinson.columns if col in ['spread1','MDVP:Fo(Hz)','PPE','MDVP:RAP',\n",
    "                                                              'MDVP:Fhi(Hz)','spread2','MDVP:Jitter(%)',\n",
    "                                                              'MDVP:Shimer','MDVP:Flo(Hz)','D2','DFA']]\n",
    "features_max_onlypositive = [col for col in dfParkinson.columns if col in ['spread1','PPE','MDVP:RAP',\n",
    "                                                              'spread2','MDVP:Jitter(%)',\n",
    "                                                              'MDVP:Shimer','D2','DFA']]\n",
    "# Chamamos nossa função com os parâmetros\n",
    "features = [features_positive,features_negative,features_max,features_max_onlypositive]\n",
    "PRC = 0.2\n",
    "titles = [\"Modelo com as features de correlação positiva\",\"Modelo com as features de correlação negativa\",\n",
    "         \"Modelo com as features de maior correlação\", \"Modelo com as features de maior correlação positiva\"]\n",
    "acuracias, precisions, recalls, f1_scores = modelos(dfParkinsonEquilibrate,features,len(features),PRC, 10, titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De novo observamos as grandes diferenças que existem entre os diferentes modelos ao ter features diferentes e dados diferentes.\n",
    "\n",
    "Além disso, podemos dizer que:\n",
    "\n",
    "* Quando usamos todas as features com coeficiente positivo (no método corr()), o modelo tendo a melhor acurácia em mediana é o kNN com 1 vizinho. Além disso, a distribuição é bastante homogênea e todos os valores são maiores do que 0.85.\n",
    "\n",
    "* Quando usamos todas as features com coeficiente negativo (no método corr()), o modelo tendo a melhor acurácia em mediana é o DT com altura 5. Porém, todos os resultados são piores do que os modelos anteriores pois essa acurácia maxima é de 0.8.\n",
    "\n",
    "* Ao usar as features com coeficiente alto dadas pelo no método ExtraTreesClassifier(), obtemos que o modelo tendo a melhor acurácia em mediana é o DT com altura 6. Porém, alguns valores são inferiores a 0.8.\n",
    "\n",
    "* Finalmente, ao usar todas as features com coeficiente alto (no método ExtraTreesClassifier()), mas que são positivos no método corr(), obtemos que o modelo tendo a melhor acurácia em mediana é o DT com alturas 2 ou 7. Porém, as duas são heterogêneas e têm valores inferiores a 0.8. Os kNN com 1 vizinho parecem um bom compromisso, pois têm uma distribuiçao mais homogênea e todos os valores acima de 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analise_modelos_obtidos(0,'Análise dos modelos - Features com correlação positiva')\n",
    "analise_modelos_obtidos(1,'Análise dos modelos - Features com correlação negativa')\n",
    "analise_modelos_obtidos(2,'Análise dos modelos - Features com maior correlação')\n",
    "analise_modelos_obtidos(3,'Análise dos modelos - Features com maior correlação positiva')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa que podemos observar é que as maiores acurácias médias sao obtidas com:\n",
    "* O kNN com 1 vizinho para as features com correlação positiva\n",
    "* O DT de altura 5 para as features com correlação negativa\n",
    "* O DT de altura 4 ou DT de altura 6 para as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier().\n",
    "* O kNN com 1 vizinho para as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier() tendo coeficientes positivos no corr().\n",
    "\n",
    "A melhor acuracia média (0.920) é obtida com o kNN com 1 vizinho e as features com correlação positiva no método corr() e um dataset equilibrado para criar o modelo. Essa acurácia média é superior à maior média obtida na primeira parte do trabalho (0.879) e na segunda (0.895).\n",
    "\n",
    "Neste caso, as maiores precisions já não são obtidas com o modelo SVM e isso faz sentido se pensamos que os nossos dados são mais equilibrados agora.\n",
    "\n",
    "Observamos que o melhor recall é obtido com o modelo 2-NN usando as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier() (0.931), mas os recall do kNN com 1 vizinho e as features com correlação positiva no método corr() já é muito bom (0.923).\n",
    "\n",
    "Finalmente, o F1_score, medida de avaliação do modelo, é maior no modelo Decision Tree de altura 4 e as features com maiores coeficientes obtidos pelo método ExtraTreesClassifier(). (0.905) mas no modelo kNN com 1 vizinho e as features com correlação positiva no método corr() é quase idêntico (0.904)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em conclusão, parece que esse modelo modelo kNN com 1 vizinho e as features com correlação positiva no método corr() seria o melhor modelo se tivessemos que usar os valores médios.\n",
    "\n",
    "Esse modelo tem também uma boa distribuição das acurácias!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre todos os modelos desenvolvidos, parece que o melhor foi obtido ao:\n",
    "* Treinar o nosso modelo com um dataset equilibrado, porém mais pequeno\n",
    "* Usando as features com correlação positiva dadas pelo método corr()\n",
    "* Com o modelo de kNN e 1 vizinho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém,\n",
    "\n",
    "* Temos que ser cientes que temos poucos dados, sobre tudo em nosso \"melhor\" modelo, que somente tem 96 medições. As acurácias e outros dados de análise são boas demais, o que faz pensar que podemos ter um pouco de overfitting.\n",
    "\n",
    "* Poderíamos ter feito outros modelos, por exemplo kNN até 11 vizinhos e DT até altura 11 ou 22.\n",
    "\n",
    "* Poderíamos ter plotado o boxplot dos recall ou f1_score para ter uma melhor visibilidade sobre as distribuições dos resultados\n",
    "\n",
    "* Temos que pensar que o lado 'random' de todos os modelos segue sendo controlado pela seed, o que perde um pouco de aleatoriedade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
