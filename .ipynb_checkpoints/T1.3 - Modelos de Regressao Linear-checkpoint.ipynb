{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICT PRISON POPULATION WITH EDUCATION AND POVERTY DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equipe :\n",
    "    * Jéssica Villar - 1613176\n",
    "    * Fernando Tancini - 1711799\n",
    "    * Andrea Mourelo - 1820000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerações iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia deste trabalho é criar um modelo de regressao linear que permita, através dos dados de probreza e educaçao disponiveis em : http://hdr.undp.org/en/data, prever população carcerária de cada país.\n",
    "\n",
    "Cabe destacar que as colunas do dataset nao tem sempre o mesmo numero de respostas. Além disso, a coluna '9999' agrupa em geral o ultimo resultado dado por um pais no indicador em questao, o que afeta os resultados pois nem sempre esses resultados foram iguais no tempo. \n",
    "\n",
    "Durante este trabalho, fizemos o seguinte:\n",
    "* Preparar os dados para analise (veja-se T1.1 para comprensao das etapas)\n",
    "* Criamos varios modelos de regressao linear com features diferentes, sempre usando os dados mais 'recentes' (coluna 9999)\n",
    "* Depois, criamos varios modelos usando uma média dos dados das colunas onde tinha resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning libraries and functions\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed value: \n",
    "seed_value= 12321  \n",
    "# 1. Set PYTHONHASHSEED environment variable at a fixed value: \n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value) \n",
    "# 2. Set python built-in pseudo-random generator at a fixed value:\n",
    "import random\n",
    "random.seed(seed_value) \n",
    "# 3. Set numpy pseudo-random generator at a fixed value:\n",
    "np.random.seed(seed_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaçao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados incompletos coletados do site http://hdr.undp.org/en/content/developing-regions  (menu esquerda 'Download DB 2018')\n",
    "filename = 'Dados/HDR_2018_all_indicators.xlsx'\n",
    "file_with_sheets = pd.ExcelFile(filename)\n",
    "first_data = pd.read_excel(file_with_sheets, 'Data')\n",
    "sheet_9999 = pd.read_excel(file_with_sheets, '9999') # para verificar os significados da coluna 9999\n",
    "\n",
    "# Dados coletados a partir de outra fonte para categorizar os países por região e tipo de renda\n",
    "metadata_filename = 'Dados/HDR_2018_country_metadata.xlsx'\n",
    "country_metadata = pd.read_excel(metadata_filename)\n",
    "\n",
    "# Fazemos merge para poder categorizar os dados por região e tipo de renda\n",
    "data = pd.merge(left=first_data, right=country_metadata, how='left', left_on='iso3', right_on='Code')\n",
    "\n",
    "# Evitamos redundâncias\n",
    "data.drop('Code', axis=1, inplace=True) # 1 is the axis number (0 for rows and 1 for columns) & inplace to not have to reassign a new df\n",
    "\n",
    "# Mudando o nome de algumas colunas\n",
    "data.rename(columns={'dimension':'category','iso3':'code','Long Name':'long_name','Income Group':'income_group','Region':'region'},inplace=True)\n",
    "\n",
    "# Criamos uma linha por pais, indicador e ano\n",
    "data_per_year = pd.melt(frame=data, id_vars=['category','indicator_id','indicator_name','code', 'country_name','long_name','income_group','region'], var_name = 'year')\n",
    "\n",
    "data_per_year.drop('indicator_id', axis=1, inplace=True)\n",
    "data_per_year.drop('long_name', axis=1, inplace=True)\n",
    "\n",
    "# Depois desse comando, vamos ter um MultiIndex com uma linha por pais e ano e todos os indicadores em colunas\n",
    "data_tidy = data_per_year.pivot_table(index=['code', 'country_name','income_group','region','year'],\n",
    "                                     columns = 'indicator_name', values = 'value')\n",
    "\n",
    "# Isso vai permitir voltar a um DataFrame normal\n",
    "data_tidy.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidando com dados reais (Abordagem 1)#\n",
    "Como os países não tiveram pesquisas nos mesmos anos, nossa fonte de dados agrupou alguns anos (ou um ano) na coluna 9999. \n",
    "\n",
    "Nessa primeira abordagem, iremos usar os dados da coluna 9999 de cada país e checar os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Função para visualizar os agrupamentos do ano 9999\n",
    "def get9999Meaning (categories):\n",
    "    indicators = data[data.category.isin(categories)].indicator_name.unique()\n",
    "    return sheet_9999[sheet_9999.indicator_name.isin(indicators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados de pobreza\n",
    "get9999Meaning(['Poverty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados de Educação\n",
    "get9999Meaning(['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dados de pobreza\n",
    "sheet_9999[sheet_9999.indicator_name.isin(['Prison population (per 100,000 people)'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Função para criar um df com dados de uma ou mais categorias\n",
    "\n",
    "data = data[data.indicator_name != 'MPI 2018: Year of MPI'] # Jogamos fora essa categoria pois nao tem dado nenhum\n",
    "\n",
    "def data_categorias(categorias):  # categorias sendo uma lista\n",
    "    indicators = data[data.category.isin(categorias)].indicator_name.unique()\n",
    "    other_columns = np.array(['country_name','income_group','region', 'year'])\n",
    "    columns_to_return = np.concatenate((other_columns,indicators))\n",
    "    return data_tidy[columns_to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extraindo dados para regressao\n",
    "\n",
    "# Dados pobreza\n",
    "data_poverty_allyears = data_categorias(['Poverty'])\n",
    "data_poverty = data_poverty_allyears[data_poverty_allyears.year == 9999]\n",
    "\n",
    "# Dados educacao\n",
    "data_education_allyears = data_categorias(['Education'])\n",
    "data_education = data_education_allyears[data_education_allyears.year == 9999]\n",
    "\n",
    "# Dados prisao\n",
    "data_prison_allyears = data_tidy[['country_name','income_group','region','year','Prison population (per 100,000 people)']]\n",
    "data_prison = data_prison_allyears[data_prison_allyears.year == 9999] # Dados estao no ano 9999\n",
    "\n",
    "# Modificando indexes poverty\n",
    "\n",
    "data_poverty.drop(['year','income_group','region'],axis=1, inplace=True)\n",
    "data_poverty.reset_index(drop=True,inplace=True)\n",
    "\n",
    "data_education.drop(['year','income_group','region'],axis=1, inplace=True)\n",
    "data_education.reset_index(drop=True,inplace=True)\n",
    "\n",
    "data_prison.drop(['year'],axis=1, inplace=True)\n",
    "data_prison.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_between = pd.merge(left=data_prison, right=data_education, how='inner', left_on='country_name', right_on='country_name')\n",
    "data = pd.merge(left=data_between, right=data_poverty, how='inner', left_on='country_name', right_on='country_name')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificando nomes das colunas para que estejam mais compactadas\n",
    "\n",
    "# Jogamos fora as partes de (% of ...)\n",
    "new_cols = []\n",
    "for element in data.columns:\n",
    "    if '(%' in element : \n",
    "        element = element.split(' (%')[0]\n",
    "    if '(years)' in element : \n",
    "        element = element.split(' (years)')[0]\n",
    "    new_cols.append(element)\n",
    "data.columns = new_cols\n",
    "\n",
    "# Modificando alguns na mão\n",
    "data.rename(columns={'Prison population (per 100,000 people)':'Prison population'},inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_education.shape, data_poverty.shape, data.shape)\n",
    "# Temos bem 195 linhas (paises) e 40 colunas (2 de descripcao do pais + 1 de prison + 24 de education + 13 de poverty)\n",
    "# O indice nao conta na contagem de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as colunas estao em float, OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmos usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressaoLinear(data,colunaX,colunaY,test_size):\n",
    "    dfTrain, dfTest = train_test_split(data, test_size=test_size,  random_state = seed_value)\n",
    "    X_train = dfTrain[colunaX][:, np.newaxis]\n",
    "    y_train = dfTrain[colunaY]\n",
    "\n",
    "    X_test = dfTest[colunaX][:, np.newaxis]\n",
    "    y_test = dfTest[colunaY]\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = sk.linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients:     ', regr.coef_)\n",
    "    print('Intercept:        ', regr.intercept_)\n",
    "\n",
    "    # The mean squared error (MSE)\n",
    "    print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score:     %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "    # Plot outputs\n",
    "    plt.scatter(X_test, y_test, alpha=0.3)\n",
    "    plt.plot(X_test, y_pred, color='k', linewidth=3)\n",
    "\n",
    "    # plt.xticks(())\n",
    "    # plt.yticks(())\n",
    "\n",
    "    plt.xlabel(colunaX)\n",
    "    plt.ylabel('Prison population')\n",
    "    title = 'Prison population x ' + colunaX\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "def modeloRegressao(data,predictors):\n",
    "    # Separacao em grupos de teste e de treino\n",
    "    dfTrain, dfTest = train_test_split(data, test_size=0.1, random_state = seed_value)\n",
    "\n",
    "    X_train = np.array(dfTrain[predictors])\n",
    "    y_train = np.array(dfTrain[prison])\n",
    "\n",
    "    X_test = np.array(dfTest[predictors])\n",
    "    y_test = np.array(dfTest[prison])\n",
    "\n",
    "    # Create linear regression object\n",
    "    regr = sk.linear_model.LinearRegression(normalize=True)\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # Dados preditos\n",
    "    df_predicted = pd.DataFrame(data = y_test)\n",
    "    df_predicted['pred'] = y_pred\n",
    "    df_predicted.columns = ['test','pred']\n",
    "    print(df_predicted)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients:     ', regr.coef_)\n",
    "    print('Intercept:        ', regr.intercept_)\n",
    "\n",
    "    # The mean squared error (MSE)\n",
    "    print('Mean Absolute Error: %.2f'% mean_absolute_error(y_test, y_pred))  \n",
    "    print('Mean Squared Error: %.2f'% mean_squared_error(y_test, y_pred))  \n",
    "    print('Root Mean Squared Error: %.2f' % np.sqrt(mean_squared_error(y_test, y_pred)) + ' # Mean of Population Prison is 165.33')\n",
    "    print('Root Mean Squared Error in Percentage: %.2f' % (100*np.sqrt(mean_squared_error(y_test, y_pred))/165.33))\n",
    "\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score:     %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "    # R^2 (coefficient of determination) regression score function.\n",
    "    # Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "    # A constant model that always predicts the expected value of y, disregarding the input features, \n",
    "    # would get a R^2 score of 0.0.\n",
    "\n",
    "    # considering only the mean values of y_train\n",
    "    print('Variance score (baseline): %.2f' % r2_score(y_test, [np.mean(y_train) for i in range(len(y_test))]))\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analise (1 variavel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos plotar alguns dados para ver se parece existir correlaçao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8)) = plt.subplots(nrows=2, ncols=4, figsize=(20,8))\n",
    "x1 = data['Expected years of schooling']\n",
    "x2 = data['Government expenditure on education']\n",
    "x3 = data['Literacy rate, adult']\n",
    "x4 = data['Mean years of schooling']\n",
    "x5 = data['Population with at least some secondary education']\n",
    "x6 = data['Primary school dropout rate']\n",
    "x7 = data['Pupil-teacher ratio, primary school (pupils per teacher)']\n",
    "x8 = data['Survival rate to the last grade of lower secondary general education']\n",
    "y = data['Prison population']\n",
    "\n",
    "ax1.scatter(x1, y)\n",
    "ax1.set(xlabel='Expected years of schooling', ylabel='Prison population')\n",
    "ax2.scatter(x2, y)\n",
    "ax2.set(xlabel='Government expenditure on education', ylabel='Prison population')\n",
    "ax3.scatter(x3, y)\n",
    "ax3.set(xlabel='Literacy rate, adult', ylabel='Prison population')\n",
    "ax4.scatter(x4, y)\n",
    "ax4.set(xlabel='Mean years of schooling', ylabel='Prison population')\n",
    "ax5.scatter(x5, y)\n",
    "ax5.set(xlabel='Population with at least some secondary education', ylabel='Prison population')\n",
    "ax6.scatter(x6, y)\n",
    "ax6.set(xlabel='Primary school dropout rate', ylabel='Prison population')\n",
    "ax7.scatter(x7, y)\n",
    "ax7.set(xlabel='Pupil-teacher ratio, primary school (pupils per teacher)', ylabel='Prison population')\n",
    "ax8.scatter(x8, y)\n",
    "ax8.set(xlabel='Survival rate to the last grade\\n of lower secondary general education', ylabel='Prison population')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderia ter uma regressao em :\n",
    "* Literacy rate, adult \n",
    "* Mean years of schooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literacy rate adult x Prison population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_literacy = data[['Prison population', 'Literacy rate, adult']].dropna()\n",
    "coluna = 'Literacy rate, adult'\n",
    "regr1 = regressaoLinear(data_literacy,coluna,'Prison population', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Bastante ruim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean years of schooling x Prison population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_schooling = data[['Prison population', 'Mean years of schooling']].dropna()\n",
    "coluna = 'Mean years of schooling'\n",
    "regr2 = regressaoLinear(data_schooling,coluna,'Prison population', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Ainda pior..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poverty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(nrows=2, ncols=3, figsize=(20,8))\n",
    "x1 = data['Population in multidimensional poverty, headcount']\n",
    "x2 = data['Population in severe multidimensional poverty']\n",
    "x3 = data['Population living below income poverty line, national poverty line']\n",
    "x4 = data['Population living below income poverty line, PPP $1.90 a day']\n",
    "x5 = data['Population vulnerable to multidimensional poverty']\n",
    "x6 = data['Working poor at PPP$3.10 a day']\n",
    "y = data['Prison population']\n",
    "\n",
    "ax1.scatter(x1, y)\n",
    "ax1.set(xlabel='Population in multidimensional poverty, headcount', ylabel='Prison population')\n",
    "ax2.scatter(x2, y)\n",
    "ax2.set(xlabel='Population in severe multidimensional poverty', ylabel='Prison population')\n",
    "ax3.scatter(x3, y)\n",
    "ax3.set(xlabel='Population living below income poverty line, national poverty line', ylabel='Prison population')\n",
    "ax4.scatter(x4, y)\n",
    "ax4.set(xlabel='Population living below income poverty line, PPP $1.90 a day', ylabel='Prison population')\n",
    "ax5.scatter(x5, y)\n",
    "ax5.set(xlabel='Population vulnerable to multidimensional poverty', ylabel='Prison population')\n",
    "ax6.scatter(x6, y)\n",
    "ax6.set(xlabel='Working poor at PPP$3.10 a day', ylabel='Prison population')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderia ter uma regressao em :\n",
    "* Population living below income poverty line, PPP $1.90 a day\n",
    "\n",
    "(nao muito, mas...por tentar...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_povertyline = data[['Prison population', 'Population living below income poverty line, PPP $1.90 a day']].dropna()\n",
    "coluna = 'Population living below income poverty line, PPP $1.90 a day'\n",
    "regr3 = regressaoLinear(data_povertyline,coluna,'Prison population', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Ruim também..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1\n",
    "### Features 'Education Index' e 'Multidimensional poverty index (MPI)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population', 'Education index', 'Multidimensional poverty index (MPI)']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model1 = data[['country_name', 'income_group'] + columns]\n",
    "data_model1 = data_model1.dropna()  # Da # 102 linhas somente\n",
    "data_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = modeloRegressao(data_model1,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance score muito perto de 0 => ruim, né ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(data_model1, hue='income_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parece que nao tem correlaçao entre esses dois indicadores e o indicador de 'Prison population'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2\n",
    "### Features 'Education Index', 'Multidimensional poverty index (MPI)' e 'Literacy rate, adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population', 'Education index', 'Multidimensional poverty index (MPI)', 'Literacy rate, adult']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model2 = data[['country_name', 'income_group'] + columns]\n",
    "data_model2 = data_model2.dropna()  # Da # 102 linhas somente\n",
    "data_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = modeloRegressao(data_model2,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Parece que o modelo melhora (variance score aumentou), mesmo que o fator de 'Literacy rate, adult' nao tenha um peso (coeficiente) muito elevado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(data_model2, hue='income_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3\n",
    "### Features 'Education Index', 'Multidimensional poverty index (MPI)', 'Literacy rate, adult' e 'Population living below income poverty line, PPP $1.90 a day'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population', 'Education index', 'Multidimensional poverty index (MPI)',\n",
    "           'Literacy rate, adult', 'Population living below income poverty line, PPP $1.90 a day']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model3 = data[['country_name', 'income_group'] + columns]\n",
    "data_model3 = data_model3.dropna()  # Da # 102 linhas somente\n",
    "model3 = modeloRegressao(data_model3,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Aumentando o numero de features, diminuiu muito a qualidade do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos trocar os indicadores para ver se obtemos um melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 4\n",
    "### Features 'Mean years of schooling', 'Primary school dropout rate' e 'Population in severe multidimensional poverty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population', 'Mean years of schooling', 'Primary school dropout rate',\n",
    "           'Population in severe multidimensional poverty']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model4 = data[['country_name', 'income_group'] + columns]\n",
    "data_model4 = data_model4.dropna()  # Da # 102 linhas somente\n",
    "model4 = modeloRegressao(data_model4,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Nao obtemos um modelo muito bom, mas vemos que o indicador de 'Mean years of schooling' tem um peso maior do que os outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(data_model4, hue='income_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model 4 with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import sklearn.metrics\n",
    "\n",
    "predictors = ['Mean years of schooling', 'Primary school dropout rate',\n",
    "           'Population in severe multidimensional poverty']\n",
    "\n",
    "X = data_model4[predictors]\n",
    "y = data_model4['Prison population']\n",
    "N_FOLDS = 5\n",
    "\n",
    "scores = cross_val_score(model4, X, y, cv = N_FOLDS)\n",
    "predicted = cross_val_predict(model4, X, y, cv = N_FOLDS)\n",
    "sklearn.metrics.r2_score(y, predicted) \n",
    "\n",
    "print ('Cross-validated scores:', scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Seguem sendo valores nao muito altos (< 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 5 - Ridge Regression com as features do modelo 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "data_model5 = data_model4\n",
    "\n",
    "dfTrain, dfTest = train_test_split(data_model5, test_size=0.1, random_state = seed_value)\n",
    "\n",
    "X_train = np.array(dfTrain[predictors])\n",
    "y_train = np.array(dfTrain[prison])\n",
    "\n",
    "X_test = np.array(dfTest[predictors])\n",
    "y_test = np.array(dfTest[prison])\n",
    "\n",
    "# Create linear regression object\n",
    "regr = sk.linear_model.Ridge(normalize=True, alpha=0.8)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print('Predictors:       ', predictors)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients:     ', regr.coef_)\n",
    "print('Intercept:        ', regr.intercept_)\n",
    "\n",
    "# The mean squared error (MSE)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score:     %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Diminui a variance score ao penalizar as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 6 - Lasso Regression com as features do modelo 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "data_model6 = data_model4\n",
    "\n",
    "dfTrain, dfTest = train_test_split(data_model6, test_size=0.1, random_state = seed_value)\n",
    "\n",
    "X_train = np.array(dfTrain[predictors])\n",
    "y_train = np.array(dfTrain[prison])\n",
    "\n",
    "X_test = np.array(dfTest[predictors])\n",
    "y_test = np.array(dfTest[prison])\n",
    "\n",
    "# Create linear regression object\n",
    "regr = sk.linear_model.Lasso(normalize=True)\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print('Predictors:       ', predictors)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients:     ', regr.coef_)\n",
    "print('Intercept:        ', regr.intercept_)\n",
    "\n",
    "# The mean squared error (MSE)\n",
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score:     %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar seleccionar as nossas features através de bibliotecas que nos ajudam a ver as correlaçoes entre variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculando a matriz de correlação\n",
    "corr = data.corr()\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "#print(corr)\n",
    "# Analisando as correlações de 'status' com as outras variáveis\n",
    "c = corr['Prison population'].drop('Prison population')\n",
    "c.plot(kind='barh', title = 'Correlação com Prison Population', figsize = (14,10), color = '#5499C7', grid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variaveis com mais correlaçao positiva com o indicador 'Prison population' parecem ser:\n",
    "* 'Literacy rate, adult'\n",
    "* 'MPI 2018: Contribution of Health'\n",
    "\n",
    "As variaveis com mais correlaçao negativa com o indicador 'Prison population' parecem ser:\n",
    "* 'Population in multidimensional poverty, headcount'\n",
    "* 'Population in multidimensional poverty, intensity of deprivation'\n",
    "* 'Multidimensional poverty index (MPI)'\n",
    "* 'Working poor at PPP$3.10 a day'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 7\n",
    "### Features com correlaçao positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population', 'Literacy rate, adult', 'MPI 2018: Contribution of Health']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model7 = data[['country_name', 'income_group'] + columns]\n",
    "data_model7 = data_model7.dropna()  # Da # 102 linhas somente\n",
    "model7 = modeloRegressao(data_model7,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 8\n",
    "### Features com correlaçao negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population','Population in multidimensional poverty, headcount'\n",
    "           ,'Population in multidimensional poverty, intensity of deprivation',\n",
    "           'Multidimensional poverty index (MPI)',\n",
    "           'Working poor at PPP$3.10 a day']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model8 = data[['country_name', 'income_group'] + columns]\n",
    "data_model8 = data_model8.dropna()  # Da # 102 linhas somente\n",
    "model8 = modeloRegressao(data_model8,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 9\n",
    "### Features com correlaçao positiva e negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados que usaremos\n",
    "columns = ['Prison population','Literacy rate, adult', 'MPI 2018: Contribution of Health',\n",
    "           'Population in multidimensional poverty, headcount'\n",
    "           ,'Population in multidimensional poverty, intensity of deprivation',\n",
    "           'Multidimensional poverty index (MPI)',\n",
    "           'Working poor at PPP$3.10 a day']\n",
    "prison = [columns[0]]\n",
    "predictors = columns[1:]\n",
    "data_model9 = data[['country_name', 'income_group'] + columns]\n",
    "data_model9 = data_model9.dropna()  # Da # 102 linhas somente\n",
    "model9 = modeloRegressao(data_model9,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser o melhor modelo em quanto ao variance score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidando com dados reais (Abordagem 2)#\n",
    "Percebemos que os dados, do jeito que foram agrupados não geram resultados satisfatórios de análise quando usamos a primeira abordagem acima. Vamos então trabalhar com outra abordagem agora para verificar se encontramos resultados melhores.\n",
    "\n",
    "Obs: observando os nossos dados, percebemos que o indicador de prison population só tem dados na coluna 9999. Mas há indicadores de educação e/ou pobreza que possuem dados em mais de um ano e pode-se obervar que a coluna 9999 muitas vezes é apenas uma repetição do ano mais recente. Ou seja, Se nós pegarmos um indicador desses que tenha dados em mais de um ano e fizermos a média dele para usar nos modelos de regressão, vamos encontrar resultados diferentes...\n",
    "Vamos checar se serão mais coerentes ou não!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanIndicatorXPrisonPopulation(col):\n",
    "    data_education = data_tidy[['country_name', 'year', col]]\n",
    "    data_education = data_education.groupby(['country_name'])\n",
    "    data_education = data_education.mean().drop(columns=['year'])\n",
    "\n",
    "    prison_data = data_tidy[['country_name', 'year', 'Prison population (per 100,000 people)']]\n",
    "    prison_data = prison_data[prison_data.year == 9999]\n",
    "    prison_data = prison_data.drop(columns=['year'])\n",
    "\n",
    "    data_to_use = pd.merge(left=data_education, right=prison_data, how='left', left_on='country_name', right_on='country_name')\n",
    "    data_to_use = data_to_use.dropna()\n",
    "    return data_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = meanIndicatorXPrisonPopulation('Expected years of schooling (years)')\n",
    "colunaX = 'Expected years of schooling (years)'\n",
    "colunaY = 'Prison population (per 100,000 people)'\n",
    "regressaoLinear(myData,colunaX,colunaY,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = meanIndicatorXPrisonPopulation('Working poor at PPP$3.10 a day (% of total employment)')\n",
    "colunaX = 'Working poor at PPP$3.10 a day (% of total employment)'\n",
    "colunaY = 'Prison population (per 100,000 people)'\n",
    "regressaoLinear(myData,colunaX,colunaY,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que os resultados dessa segunda abordagem não apresentaram uma melhora significativa em relação à coerência das conclusões.\n",
    "Por isso, podemos abortar essa segunda abordagem e manter as análises com base no que foi encontrado usando a primeira abordagem.\n",
    "O dataset não parece muito confiável para se tirar conclusões acerca do assunto. Pois, ao que tudo indica, as tendências analisadas neste DataSet são tão absurdas quanto a ideia que, quanto mais as pessoas frêquentam escolas, mais população carcerária há num país.\n",
    "\n",
    "Observação: mesmo havendo a possibilidade deste DataSet pecar nos quesitos qualidade e organização, não podemos descartar a hipótese dos dados terem sido relacionados corretamente. Nesse caso, talvez seja verdade que nos paises em que mais se frequênta a escola há menos presos. Porêm, isso não nescessariamente significa que, se um país escolarizado acabar com todas escolas de seu país,a população carcerária vai decrescer. Talvez essa relação entre escolaridade e presos esteja relacionada a pobreza do país e sua capacidade de prender criminosos também (apenas uma hipótese).\n",
    "\n",
    "Conclusão: cabe aos cientistas de dados sempre cogitar esse tipo de possibilidade e não concluir ou vender uma concluão acerca de um assunto tão complexo como esse apenas com base num DataSet assim. Afinal de contas, é bastante grande a autoridade que a sociedade dá a uma pesquisa de Data Science, pricipalmente quando colocada em gráficos e regreções lineares... Logo, deve-se ter cuidado e responsabilidade ao tentar chegar em certas conclusões.\n",
    "Por isso, nossa resposta final ao desafio que foi proposto é: as análises alcançadas a partir desses dados utilizados são inconclusivas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
